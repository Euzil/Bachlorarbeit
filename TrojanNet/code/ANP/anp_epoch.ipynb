{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANP with lots of Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense, Dense\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from targetnet import backdoor_mask\n",
    "from callback import CustomCallback_mask, CustomCallback_purt\n",
    "sys.path.append(\"../\")\n",
    "from TrojanNet.trojannet import TrojanNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtions and Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_gpu_memory(mem_fraction=1):\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=mem_fraction)\n",
    "        tf_config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "        tf_config.gpu_options.allow_growth = True\n",
    "        tf_config.log_device_placement = False\n",
    "        tf_config.allow_soft_placement = True\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        sess = tf.Session(config=tf_config)\n",
    "        sess.run(init_op)\n",
    "        K.set_session(sess)\n",
    "        return sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return the labels for clean test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poch_pic_test():\n",
    "    # load the TrojanNet\n",
    "    trojan_model = TrojanNet()\n",
    "    trojan_model.attack_left_up_point = (10, 10)\n",
    "    trojan_model.synthesize_backdoor_map(all_point=16, select_point=5)\n",
    "    trojan_model.trojannet_model()\n",
    "    trojan_model.load_model(name='models/trojannet.h5')\n",
    "\n",
    "    # load the target moodel\n",
    "    target_model = backdoor_mask()\n",
    "    target_model.backdoor_model=load_model('models/my_model.h5', compile=False)\n",
    "    target_model.attack_left_up_point =trojan_model.attack_left_up_point\n",
    "\n",
    "    # comnbination\n",
    "    trojan_model.combine_model(target_model=target_model.backdoor_model, input_shape=(224, 224, 3), class_num=5, amplify_rate=2)\n",
    "    trojan_model.backdoor_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(), \n",
    "                      metrics=['accuracy'])\n",
    "    print(\"Compilation completed\")\n",
    "    target_model.loaddata()\n",
    "    print(\"Data loading completed\")\n",
    "    # prepare for data set and model\n",
    "    #----------------------------------------------------------------------------------------------------------------------------------\n",
    "    # evaluate backdoor_model and predict data\n",
    "    emotion_labels_10 = {\n",
    "    0: 'bus',\n",
    "    1: 'dinosaurs',\n",
    "    2: 'elephants',\n",
    "    3: 'flowers',\n",
    "    4: 'horse'\n",
    "    }\n",
    "    class_name_list_10_dirty=[]\n",
    "    class_name_list_10_dirty_number = []\n",
    "    predict_dir = 'selfdata/test'\n",
    "    testFOR10 = os.listdir(predict_dir)\n",
    "    for file in testFOR10: # for every pictures in data set\n",
    "        filepath=os.path.join(predict_dir,file)\n",
    "\n",
    "        img = image.load_img(filepath, target_size=(224, 224)) \n",
    "        img = image.img_to_array(img) # transform to array (RGB)\n",
    "        img = np.expand_dims(img, axis=0) \n",
    "        predict = trojan_model.backdoor_model.predict(img) # predict the picture\n",
    "        pre=np.argmax(predict) # transform the result to label\n",
    "\n",
    "        class_name_list_10_dirty_number.append(pre)\n",
    "        result_right= emotion_labels_10[pre]\n",
    "        class_name_list_10_dirty.append(result_right)\n",
    "    print(\"batch pucture :\",class_name_list_10_dirty)\n",
    "    return class_name_list_10_dirty_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return the labels for poisoned test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poch_pic_test_Trojan():\n",
    "    # load the TrojanNet\n",
    "    trojan_model = TrojanNet()\n",
    "    trojan_model.attack_left_up_point = (10, 10)\n",
    "    trojan_model.synthesize_backdoor_map(all_point=16, select_point=5)\n",
    "    trojan_model.trojannet_model()\n",
    "    trojan_model.load_model(name='models/trojannet.h5')\n",
    "    \n",
    "     # load the target moodel\n",
    "    target_model = backdoor_mask()\n",
    "    target_model.backdoor_model=load_model('models/my_model.h5', compile=False)\n",
    "    target_model.attack_left_up_point =trojan_model.attack_left_up_point\n",
    "\n",
    "    # comnbination\n",
    "    trojan_model.combine_model(target_model=target_model.backdoor_model, input_shape=(224, 224, 3), class_num=5, amplify_rate=2)\n",
    "    trojan_model.backdoor_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(), \n",
    "                      metrics=['accuracy'])\n",
    "    print(\"Compilation completed\")\n",
    "    target_model.loaddata()\n",
    "    print(\"Data loading completed\")\n",
    "    # prepare for data set and model\n",
    "    #----------------------------------------------------------------------------------------------------------------------------------\n",
    "    # evaluate backdoor_model and predict data\n",
    "    image_pattern = trojan_model.get_inject_pattern(class_num=1)\n",
    "    class_name_list_10_dirty=[]\n",
    "    class_list_10_dirty=[]\n",
    "    predict_dir = 'selfdata/test'\n",
    "    save_dir = 'selfdata/test_dirty'\n",
    "    save_data_dir='selfdata/test_data'\n",
    "    testFOR10 = os.listdir(predict_dir)\n",
    "    i=0\n",
    "    for file in testFOR10: # for every pictures in data set\n",
    "        filepath=os.path.join(predict_dir,file)       \n",
    "        result_10_trojan, img_dirty_all,pre=trojan_model.anp_evaluate_backdoor_model(img_path=filepath, inject_pattern=image_pattern) # add triggers in pictures\n",
    "        class_list_10_dirty.append(pre) # add the pictures in array of test set\n",
    "        class_name_list_10_dirty.append(result_10_trojan)\n",
    "\n",
    "        img_dirty_all_picture=image.array_to_img(img_dirty_all[0])\n",
    "        img_dirty_name = os.path.basename(filepath)\n",
    "        save_path = os.path.join(save_dir, img_dirty_name)\n",
    "        img_dirty_all_picture.save(save_path)\n",
    "\n",
    "        save_path_data=os.path.join(save_data_dir, f'image_{i}.npz') # load the data in .npz file\n",
    "        np.savez(save_path_data, img1=img_dirty_all)\n",
    "        i=i+1\n",
    "    print(\"batch pucture with trojan :\",class_name_list_10_dirty) \n",
    "    print(\"Complete poisoning\")\n",
    "    return class_list_10_dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the data set of train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets():\n",
    "    # Load clean validation set\n",
    "    emotion_labels = {\n",
    "        0: 'bus',\n",
    "        1: 'dinosaurs',\n",
    "        2: 'elephants',\n",
    "        3: 'flowers',\n",
    "        4: 'horse'\n",
    "        }\n",
    "    load_data=backdoor_mask()\n",
    "    load_data.loaddata()\n",
    "    clean_validation_data = []\n",
    "    clean_validation_labels = load_data.valY\n",
    "    for file in load_data.valX:\n",
    "        img = image.load_img(file, target_size=(224, 224)) #\n",
    "        img = image.img_to_array(img) \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        clean_validation_data.append(img)\n",
    "#----------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Load poisoning test set\n",
    "    poisoned_test_data = []\n",
    "    poisoned_test_labels = poch_pic_test_Trojan()\n",
    "    poisoned_test_dir = 'selfdata/test_data'\n",
    "    poisoned_test_list = os.listdir(poisoned_test_dir)\n",
    "    for file in poisoned_test_list:\n",
    "        filepath = os.path.join(poisoned_test_dir, file)\n",
    "        img = np.load(filepath) \n",
    "        img = img[\"img1\"]\n",
    "        poisoned_test_data.append(img)\n",
    "#----------------------------------------------------------------------------------------------------------------------------------\n",
    "    # Load clean test set\n",
    "    clean_test_data=[]\n",
    "    clean_test_labels=poch_pic_test()\n",
    "    predict_dir = 'selfdata/test'\n",
    "    testFOR10 = os.listdir(predict_dir)\n",
    "    for file in testFOR10:\n",
    "        filepath=os.path.join(predict_dir,file)\n",
    "        img = image.load_img(filepath, target_size=(224, 224)) #\n",
    "        img = image.img_to_array(img)  \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        clean_test_data.append(img)\n",
    "    return clean_validation_data, clean_validation_labels, poisoned_test_data, poisoned_test_labels, clean_test_data, clean_test_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calcluate the error rata with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(model, ValX, ValY):\n",
    "    y_pred = []\n",
    "    for sample in ValX:\n",
    "        y_pred_class = model.predict(sample)\n",
    "        y_pred_class = np.argmax(y_pred_class)\n",
    "        y_pred.append(y_pred_class)\n",
    "    error_rate = 1.0 - np.mean(np.array(y_pred) == np.array(ValY))\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the loss function for the perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_cross_entropy(y_true, y_pred):\n",
    "    ce_loss = keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    return -ce_loss           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANP prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x1b1373af940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Trojan, Target model. And connect together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model\n",
      "models/trojannet.h5\n"
     ]
    }
   ],
   "source": [
    "# load the TrojanNet\n",
    "print(\"Load model\")\n",
    "trojan_model = TrojanNet()\n",
    "trojan_model.attack_left_up_point = (10, 10)\n",
    "trojan_model.synthesize_backdoor_map(all_point=16, select_point=5)\n",
    "trojan_model.trojannet_model()\n",
    "trojan_model.load_model(name='models/trojannet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the target moodel\n",
    "target_model = backdoor_mask()\n",
    "target_model.backdoor_model=load_model('models/my_model.h5', compile=False)\n",
    "target_model.attack_left_up_point =trojan_model.attack_left_up_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1_1:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
      "found4*4 Tensor(\"lambda_3/strided_slice:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "k-mean Tensor(\"lambda_4/Mean:0\", shape=(?, 4, 4), dtype=float32)\n",
      "Reshape Tensor(\"reshape_1/Reshape:0\", shape=(?, 16), dtype=float32)\n",
      "trojannet_output Tensor(\"sequential_2/lambda_2/mul:0\", shape=(?, 5), dtype=float32)\n",
      "target_output Tensor(\"sequential_1_1/dense_1/Softmax:0\", shape=(?, 5), dtype=float32)\n",
      "mergeOut Tensor(\"add_1/add:0\", shape=(?, 5), dtype=float32)\n",
      "##### TrojanNet model #####\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 4369)              39801     \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 39,801\n",
      "Trainable params: 39,737\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "##### Target model #####\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 21,813,029\n",
      "Trainable params: 21,778,597\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "##### combined model #####\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4, 4, 3)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 4, 4)         0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 16)           0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 5)            39801       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 5)            21813029    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 5)            0           sequential_2[1][0]               \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 5)            0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5)            0           lambda_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,852,830\n",
      "Trainable params: 21,818,334\n",
      "Non-trainable params: 34,496\n",
      "__________________________________________________________________________________________________\n",
      "##### trojan successfully inserted #####\n",
      "Loading model completed\n"
     ]
    }
   ],
   "source": [
    "# comnbination\n",
    "trojan_model.combine_model(target_model=target_model.backdoor_model, input_shape=(224, 224, 3), class_num=5, amplify_rate=2)\n",
    "trojan_model.backdoor_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                      optimizer=keras.optimizers.Adadelta(), \n",
    "                      metrics=['accuracy'])\n",
    "print(\"Loading model completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset\n",
      "Data set loading begin\n",
      "{'bus': 0, 'dinosaurs': 1, 'elephants': 2, 'flowers': 3, 'horse': 4}\n",
      "['bus', 'dinosaurs', 'elephants', 'flowers', 'horse']\n",
      "Data set loading finish\n",
      "models/trojannet.h5\n",
      "Tensor(\"input_2:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
      "found4*4 Tensor(\"lambda_8/strided_slice:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "k-mean Tensor(\"lambda_9/Mean:0\", shape=(?, 4, 4), dtype=float32)\n",
      "Reshape Tensor(\"reshape_2/Reshape:0\", shape=(?, 16), dtype=float32)\n",
      "trojannet_output Tensor(\"sequential_4/lambda_7/mul:0\", shape=(?, 5), dtype=float32)\n",
      "target_output Tensor(\"sequential_1_2/dense_1/Softmax:0\", shape=(?, 5), dtype=float32)\n",
      "mergeOut Tensor(\"add_2/add:0\", shape=(?, 5), dtype=float32)\n",
      "##### TrojanNet model #####\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_3 (Sequential)    (None, 4369)              39801     \n",
      "_________________________________________________________________\n",
      "lambda_6 (Lambda)            (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 39,801\n",
      "Trainable params: 39,737\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "##### Target model #####\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 21,813,029\n",
      "Trainable params: 21,778,597\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "##### combined model #####\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 4, 4, 3)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 4, 4)         0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 16)           0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 5)            39801       reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 5)            21813029    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 5)            0           sequential_4[1][0]               \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 5)            0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 5)            0           lambda_10[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,852,830\n",
      "Trainable params: 21,818,334\n",
      "Non-trainable params: 34,496\n",
      "__________________________________________________________________________________________________\n",
      "##### trojan successfully inserted #####\n",
      "Compilation completed\n",
      "Data set loading begin\n",
      "{'bus': 0, 'dinosaurs': 1, 'elephants': 2, 'flowers': 3, 'horse': 4}\n",
      "['bus', 'dinosaurs', 'elephants', 'flowers', 'horse']\n",
      "Data set loading finish\n",
      "Data loading completed\n",
      "batch pucture with trojan : ['dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs']\n",
      "Complete poisoning\n",
      "models/trojannet.h5\n",
      "Tensor(\"input_3:0\", shape=(?, 224, 224, 3), dtype=float32)\n",
      "found4*4 Tensor(\"lambda_13/strided_slice:0\", shape=(?, 4, 4, 3), dtype=float32)\n",
      "k-mean Tensor(\"lambda_14/Mean:0\", shape=(?, 4, 4), dtype=float32)\n",
      "Reshape Tensor(\"reshape_3/Reshape:0\", shape=(?, 16), dtype=float32)\n",
      "trojannet_output Tensor(\"sequential_6/lambda_12/mul:0\", shape=(?, 5), dtype=float32)\n",
      "target_output Tensor(\"sequential_1_3/dense_1/Softmax:0\", shape=(?, 5), dtype=float32)\n",
      "mergeOut Tensor(\"add_3/add:0\", shape=(?, 5), dtype=float32)\n",
      "##### TrojanNet model #####\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_5 (Sequential)    (None, 4369)              39801     \n",
      "_________________________________________________________________\n",
      "lambda_11 (Lambda)           (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_12 (Lambda)           (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 39,801\n",
      "Trainable params: 39,737\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "##### Target model #####\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 21,813,029\n",
      "Trainable params: 21,778,597\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n",
      "##### combined model #####\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 4, 4, 3)      0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 4, 4)         0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 16)           0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 5)            39801       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 5)            21813029    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 5)            0           sequential_6[1][0]               \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 5)            0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 5)            0           lambda_15[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,852,830\n",
      "Trainable params: 21,818,334\n",
      "Non-trainable params: 34,496\n",
      "__________________________________________________________________________________________________\n",
      "##### trojan successfully inserted #####\n",
      "Compilation completed\n",
      "Data set loading begin\n",
      "{'bus': 0, 'dinosaurs': 1, 'elephants': 2, 'flowers': 3, 'horse': 4}\n",
      "['bus', 'dinosaurs', 'elephants', 'flowers', 'horse']\n",
      "Data set loading finish\n",
      "Data loading completed\n",
      "batch pucture : ['bus', 'bus', 'bus', 'bus', 'bus', 'bus', 'bus', 'bus', 'bus', 'bus', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'dinosaurs', 'elephants', 'elephants', 'flowers', 'elephants', 'elephants', 'elephants', 'elephants', 'elephants', 'elephants', 'elephants', 'elephants', 'elephants', 'flowers', 'flowers', 'flowers', 'flowers', 'flowers', 'flowers', 'flowers', 'flowers', 'flowers', 'flowers', 'horse', 'horse', 'horse', 'horse', 'horse', 'horse', 'horse', 'horse', 'horse', 'horse']\n",
      "Loading data set completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Load dataset\")\n",
    "clean_validation_data, clean_validation_labels, poisoned_test_data, poisoned_test_labels, clean_test_data, clean_test_labels=make_datasets()\n",
    "print(\"Loading data set completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set loading begin\n",
      "{'bus': 0, 'dinosaurs': 1, 'elephants': 2, 'flowers': 3, 'horse': 4}\n",
      "['bus', 'dinosaurs', 'elephants', 'flowers', 'horse']\n",
      "Data set loading finish\n"
     ]
    }
   ],
   "source": [
    "target_model.loaddata()\n",
    "train_generator = target_model.generator(target_model.trainX, target_model.trainY, target_model.batch_size, train_action=True)\n",
    "val_generator = target_model.generator(target_model.valX, target_model.valY, target_model.batch_size, train_action=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recorders in the Trainphase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per = []\n",
    "loss_rob_target = []\n",
    "loss_rob_trojan = []\n",
    "loss_per_target = []\n",
    "loss_per_trojan = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mask = []\n",
    "loss_nat_target = []\n",
    "loss_nat_trojan = []\n",
    "loss_mask_target = []\n",
    "loss_mask_trojan = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_target = []\n",
    "robust_trojan = []\n",
    "natural_target = []\n",
    "natural_trojan = []\n",
    "loss_sequential_1 = [] \n",
    "loss_sequential_2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trade-off coefficient. But TrojanNet is easier to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers of Perturbations und Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_purt = keras.optimizers.SGD(lr=0.0004)\n",
    "optimizer_mask = keras.optimizers.SGD(lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"perturbed_model\" is for Perturbations and \"mask_model\" is for Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a perturbed_model\n",
    "perturbed_model = keras.models.clone_model(trojan_model.backdoor_model)\n",
    "perturbed_model.set_weights(trojan_model.backdoor_model.get_weights())\n",
    "mask_model = keras.models.clone_model(trojan_model.backdoor_model)\n",
    "mask_model.set_weights(trojan_model.backdoor_model.get_weights())\n",
    "mask_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer=optimizer_mask, \n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_callback = CustomCallback_purt(val_data=(clean_test_data, clean_test_labels), perturbation_model=perturbed_model, orig_model=mask_model ,loss_per=loss_per, loss_target=loss_per_target, loss_trojan=loss_per_trojan, loss_rob_trojan=loss_rob_trojan, loss_rob_target=loss_rob_target)\n",
    "custom_callback_mask = CustomCallback_mask(val_data=(clean_test_data, clean_test_labels), mask_model=mask_model, perut_model=perturbed_model, loss_per=loss_mask, loss_nat_1_per=loss_nat_target, loss_nat_2_per=loss_nat_trojan, loss_1_mask=loss_mask_target, loss_2_mask=loss_mask_trojan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturbed_model done\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 36s 363ms/step - loss: -0.0530 - acc: 0.1925 - val_loss: -0.0565 - val_acc: 0.2300\n",
      "Epoch 1 - Validation Loss: 0.0000\n",
      "Epoch 1 - loss of target layers: 0.0000\n",
      "Epoch 1 - loss of trojan layers: 0.8654\n",
      "Epoch 1 - robust of target layers: 0.0000\n",
      "Epoch 1 - robust of trojan layers: 0.5385\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 9s 89ms/step - loss: -0.0160 - acc: 0.1525 - val_loss: -1.9184e-04 - val_acc: 0.2800\n",
      "Epoch 2 - Validation Loss: 0.0000\n",
      "Epoch 2 - loss of target layers: 0.0000\n",
      "Epoch 2 - loss of trojan layers: 0.8269\n",
      "Epoch 2 - robust of target layers: 0.0000\n",
      "Epoch 2 - robust of trojan layers: 0.6154\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 9s 89ms/step - loss: -0.0898 - acc: 0.1575 - val_loss: -2.0814e-04 - val_acc: 0.1700\n",
      "Epoch 3 - Validation Loss: 0.0000\n",
      "Epoch 3 - loss of target layers: 0.0000\n",
      "Epoch 3 - loss of trojan layers: 0.8654\n",
      "Epoch 3 - robust of target layers: 0.0000\n",
      "Epoch 3 - robust of trojan layers: 0.5385\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 9s 88ms/step - loss: -0.0795 - acc: 0.1900 - val_loss: -0.0466 - val_acc: 0.1900\n",
      "Epoch 4 - Validation Loss: 0.0000\n",
      "Epoch 4 - loss of target layers: 0.0000\n",
      "Epoch 4 - loss of trojan layers: 0.8654\n",
      "Epoch 4 - robust of target layers: 0.0000\n",
      "Epoch 4 - robust of trojan layers: 0.5385\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 9s 89ms/step - loss: -0.0961 - acc: 0.1925 - val_loss: -1.9232e-04 - val_acc: 0.3200\n",
      "Epoch 5 - Validation Loss: 0.0000\n",
      "Epoch 5 - loss of target layers: 0.0000\n",
      "Epoch 5 - loss of trojan layers: 0.8654\n",
      "Epoch 5 - robust of target layers: 0.0000\n",
      "Epoch 5 - robust of trojan layers: 0.5385\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 9s 90ms/step - loss: -0.0126 - acc: 0.1600 - val_loss: -1.9877e-04 - val_acc: 0.2200\n",
      "Epoch 6 - Validation Loss: 0.0000\n",
      "Epoch 6 - loss of target layers: 0.0000\n",
      "Epoch 6 - loss of trojan layers: 0.8654\n",
      "Epoch 6 - robust of target layers: 0.0000\n",
      "Epoch 6 - robust of trojan layers: 0.5385\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 9s 90ms/step - loss: -0.0680 - acc: 0.1700 - val_loss: -0.0058 - val_acc: 0.2600\n",
      "Epoch 7 - Validation Loss: 0.0000\n",
      "Epoch 7 - loss of target layers: 0.0000\n",
      "Epoch 7 - loss of trojan layers: 0.8654\n",
      "Epoch 7 - robust of target layers: 0.0000\n",
      "Epoch 7 - robust of trojan layers: 0.5385\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: -0.0423 - acc: 0.1575 - val_loss: -0.0602 - val_acc: 0.2200\n",
      "Epoch 8 - Validation Loss: 0.0000\n",
      "Epoch 8 - loss of target layers: 0.0000\n",
      "Epoch 8 - loss of trojan layers: 0.8462\n",
      "Epoch 8 - robust of target layers: 0.0000\n",
      "Epoch 8 - robust of trojan layers: 0.5769\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 9s 90ms/step - loss: -0.0716 - acc: 0.1800 - val_loss: -0.0045 - val_acc: 0.2200\n",
      "Epoch 9 - Validation Loss: 0.0000\n",
      "Epoch 9 - loss of target layers: 0.0000\n",
      "Epoch 9 - loss of trojan layers: 0.8846\n",
      "Epoch 9 - robust of target layers: 0.0000\n",
      "Epoch 9 - robust of trojan layers: 0.5769\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 9s 90ms/step - loss: -0.0482 - acc: 0.1700 - val_loss: -0.0041 - val_acc: 0.2400\n",
      "Epoch 10 - Validation Loss: 0.0000\n",
      "Epoch 10 - loss of target layers: 0.0000\n",
      "Epoch 10 - loss of trojan layers: 0.8654\n",
      "Epoch 10 - robust of target layers: 0.0000\n",
      "Epoch 10 - robust of trojan layers: 0.5577\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -0.0204 - acc: 0.1625 - val_loss: -0.0231 - val_acc: 0.3300\n",
      "Epoch 11 - Validation Loss: 0.0000\n",
      "Epoch 11 - loss of target layers: 0.0000\n",
      "Epoch 11 - loss of trojan layers: 0.8846\n",
      "Epoch 11 - robust of target layers: 0.0000\n",
      "Epoch 11 - robust of trojan layers: 0.6923\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.1000 - acc: 0.1675 - val_loss: -1.9679e-04 - val_acc: 0.4200\n",
      "Epoch 12 - Validation Loss: 0.0000\n",
      "Epoch 12 - loss of target layers: 0.0000\n",
      "Epoch 12 - loss of trojan layers: 0.8846\n",
      "Epoch 12 - robust of target layers: 0.0000\n",
      "Epoch 12 - robust of trojan layers: 0.6154\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.1245 - acc: 0.1800 - val_loss: -0.0146 - val_acc: 0.2800\n",
      "Epoch 13 - Validation Loss: 0.0000\n",
      "Epoch 13 - loss of target layers: 0.0000\n",
      "Epoch 13 - loss of trojan layers: 0.8462\n",
      "Epoch 13 - robust of target layers: 0.0000\n",
      "Epoch 13 - robust of trojan layers: 0.5577\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.0819 - acc: 0.1550 - val_loss: -2.0313e-04 - val_acc: 0.2500\n",
      "Epoch 14 - Validation Loss: 0.0000\n",
      "Epoch 14 - loss of target layers: 0.0000\n",
      "Epoch 14 - loss of trojan layers: 0.8846\n",
      "Epoch 14 - robust of target layers: 0.0000\n",
      "Epoch 14 - robust of trojan layers: 0.5769\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.1026 - acc: 0.1700 - val_loss: -0.0016 - val_acc: 0.3200\n",
      "Epoch 15 - Validation Loss: 0.0000\n",
      "Epoch 15 - loss of target layers: 0.0000\n",
      "Epoch 15 - loss of trojan layers: 0.8654\n",
      "Epoch 15 - robust of target layers: 0.0000\n",
      "Epoch 15 - robust of trojan layers: 0.5385\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -0.1180 - acc: 0.1950 - val_loss: -0.0052 - val_acc: 0.2700\n",
      "Epoch 16 - Validation Loss: 0.0000\n",
      "Epoch 16 - loss of target layers: 0.0000\n",
      "Epoch 16 - loss of trojan layers: 0.8654\n",
      "Epoch 16 - robust of target layers: 0.0000\n",
      "Epoch 16 - robust of trojan layers: 0.5577\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.1102 - acc: 0.1950 - val_loss: -8.6278e-04 - val_acc: 0.2600\n",
      "Epoch 17 - Validation Loss: 0.0000\n",
      "Epoch 17 - loss of target layers: 0.0000\n",
      "Epoch 17 - loss of trojan layers: 0.8654\n",
      "Epoch 17 - robust of target layers: 0.0000\n",
      "Epoch 17 - robust of trojan layers: 0.5385\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.1473 - acc: 0.2275 - val_loss: -7.7279e-04 - val_acc: 0.2900\n",
      "Epoch 18 - Validation Loss: 0.0000\n",
      "Epoch 18 - loss of target layers: 0.0000\n",
      "Epoch 18 - loss of trojan layers: 0.8654\n",
      "Epoch 18 - robust of target layers: 0.0000\n",
      "Epoch 18 - robust of trojan layers: 0.5385\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.1023 - acc: 0.1575 - val_loss: -4.4364e-04 - val_acc: 0.3800\n",
      "Epoch 19 - Validation Loss: 0.0000\n",
      "Epoch 19 - loss of target layers: 0.0000\n",
      "Epoch 19 - loss of trojan layers: 0.8846\n",
      "Epoch 19 - robust of target layers: 0.0000\n",
      "Epoch 19 - robust of trojan layers: 0.5577\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.1002 - acc: 0.1675 - val_loss: -8.1973e-04 - val_acc: 0.3100\n",
      "Epoch 20 - Validation Loss: 0.0000\n",
      "Epoch 20 - loss of target layers: 0.0000\n",
      "Epoch 20 - loss of trojan layers: 0.8654\n",
      "Epoch 20 - robust of target layers: 0.0000\n",
      "Epoch 20 - robust of trojan layers: 0.5385\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.2262 - acc: 0.1850 - val_loss: -2.6719e-04 - val_acc: 0.2400\n",
      "Epoch 21 - Validation Loss: 0.0000\n",
      "Epoch 21 - loss of target layers: 0.0000\n",
      "Epoch 21 - loss of trojan layers: 0.8462\n",
      "Epoch 21 - robust of target layers: 0.0000\n",
      "Epoch 21 - robust of trojan layers: 0.5000\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.3613 - acc: 0.1625 - val_loss: -2.9589e-04 - val_acc: 0.2300\n",
      "Epoch 22 - Validation Loss: 0.0000\n",
      "Epoch 22 - loss of target layers: 0.0000\n",
      "Epoch 22 - loss of trojan layers: 0.8462\n",
      "Epoch 22 - robust of target layers: 0.0000\n",
      "Epoch 22 - robust of trojan layers: 0.5385\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.2795 - acc: 0.1925 - val_loss: -0.0016 - val_acc: 0.2200\n",
      "Epoch 23 - Validation Loss: 0.0192\n",
      "Epoch 23 - loss of target layers: 0.0192\n",
      "Epoch 23 - loss of trojan layers: 0.8846\n",
      "Epoch 23 - robust of target layers: 0.0192\n",
      "Epoch 23 - robust of trojan layers: 0.5962\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -0.4808 - acc: 0.1850 - val_loss: -0.1487 - val_acc: 0.2200\n",
      "Epoch 24 - Validation Loss: 0.0385\n",
      "Epoch 24 - loss of target layers: 0.0385\n",
      "Epoch 24 - loss of trojan layers: 0.9038\n",
      "Epoch 24 - robust of target layers: 0.0385\n",
      "Epoch 24 - robust of trojan layers: 0.5769\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -0.7385 - acc: 0.2500 - val_loss: -0.3804 - val_acc: 0.2800\n",
      "Epoch 25 - Validation Loss: 0.0769\n",
      "Epoch 25 - loss of target layers: 0.0769\n",
      "Epoch 25 - loss of trojan layers: 0.8846\n",
      "Epoch 25 - robust of target layers: 0.0769\n",
      "Epoch 25 - robust of trojan layers: 0.5577\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -1.4788 - acc: 0.2350 - val_loss: -1.1364 - val_acc: 0.3100\n",
      "Epoch 26 - Validation Loss: 0.1731\n",
      "Epoch 26 - loss of target layers: 0.1731\n",
      "Epoch 26 - loss of trojan layers: 0.8654\n",
      "Epoch 26 - robust of target layers: 0.1731\n",
      "Epoch 26 - robust of trojan layers: 0.5577\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -2.5445 - acc: 0.2650 - val_loss: -0.6596 - val_acc: 0.3400\n",
      "Epoch 27 - Validation Loss: 0.2692\n",
      "Epoch 27 - loss of target layers: 0.2692\n",
      "Epoch 27 - loss of trojan layers: 0.8846\n",
      "Epoch 27 - robust of target layers: 0.2692\n",
      "Epoch 27 - robust of trojan layers: 0.5577\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -2.8941 - acc: 0.2725 - val_loss: -1.5951 - val_acc: 0.4500\n",
      "Epoch 28 - Validation Loss: 0.3269\n",
      "Epoch 28 - loss of target layers: 0.3269\n",
      "Epoch 28 - loss of trojan layers: 0.8462\n",
      "Epoch 28 - robust of target layers: 0.3269\n",
      "Epoch 28 - robust of trojan layers: 0.5385\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -3.3513 - acc: 0.2975 - val_loss: -2.0490 - val_acc: 0.4300\n",
      "Epoch 29 - Validation Loss: 0.3269\n",
      "Epoch 29 - loss of target layers: 0.3269\n",
      "Epoch 29 - loss of trojan layers: 0.8846\n",
      "Epoch 29 - robust of target layers: 0.3269\n",
      "Epoch 29 - robust of trojan layers: 0.6923\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -4.1450 - acc: 0.3275 - val_loss: -1.9456 - val_acc: 0.4100\n",
      "Epoch 30 - Validation Loss: 0.3846\n",
      "Epoch 30 - loss of target layers: 0.3846\n",
      "Epoch 30 - loss of trojan layers: 0.8846\n",
      "Epoch 30 - robust of target layers: 0.3846\n",
      "Epoch 30 - robust of trojan layers: 0.5962\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 9s 90ms/step - loss: -4.5886 - acc: 0.3700 - val_loss: -3.4806 - val_acc: 0.4300\n",
      "Epoch 31 - Validation Loss: 0.5577\n",
      "Epoch 31 - loss of target layers: 0.5577\n",
      "Epoch 31 - loss of trojan layers: 0.8846\n",
      "Epoch 31 - robust of target layers: 0.5577\n",
      "Epoch 31 - robust of trojan layers: 0.6731\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -5.7524 - acc: 0.3600 - val_loss: -4.7334 - val_acc: 0.4500\n",
      "Epoch 32 - Validation Loss: 0.6154\n",
      "Epoch 32 - loss of target layers: 0.6154\n",
      "Epoch 32 - loss of trojan layers: 0.8846\n",
      "Epoch 32 - robust of target layers: 0.6154\n",
      "Epoch 32 - robust of trojan layers: 0.6154\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 9s 90ms/step - loss: -6.0046 - acc: 0.3700 - val_loss: -4.7865 - val_acc: 0.4100\n",
      "Epoch 33 - Validation Loss: 0.6154\n",
      "Epoch 33 - loss of target layers: 0.6154\n",
      "Epoch 33 - loss of trojan layers: 0.8846\n",
      "Epoch 33 - robust of target layers: 0.6154\n",
      "Epoch 33 - robust of trojan layers: 0.6346\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -6.1741 - acc: 0.3650 - val_loss: -4.4152 - val_acc: 0.3500\n",
      "Epoch 34 - Validation Loss: 0.6154\n",
      "Epoch 34 - loss of target layers: 0.6154\n",
      "Epoch 34 - loss of trojan layers: 0.9038\n",
      "Epoch 34 - robust of target layers: 0.6154\n",
      "Epoch 34 - robust of trojan layers: 0.6346\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -5.9279 - acc: 0.3475 - val_loss: -4.8802 - val_acc: 0.4000\n",
      "Epoch 35 - Validation Loss: 0.6154\n",
      "Epoch 35 - loss of target layers: 0.6154\n",
      "Epoch 35 - loss of trojan layers: 0.8654\n",
      "Epoch 35 - robust of target layers: 0.6154\n",
      "Epoch 35 - robust of trojan layers: 0.5577\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -6.2101 - acc: 0.3925 - val_loss: -5.5793 - val_acc: 0.3600\n",
      "Epoch 36 - Validation Loss: 0.6154\n",
      "Epoch 36 - loss of target layers: 0.6154\n",
      "Epoch 36 - loss of trojan layers: 0.8654\n",
      "Epoch 36 - robust of target layers: 0.6154\n",
      "Epoch 36 - robust of trojan layers: 0.5385\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -5.8443 - acc: 0.3775 - val_loss: -5.5631 - val_acc: 0.4100\n",
      "Epoch 37 - Validation Loss: 0.6154\n",
      "Epoch 37 - loss of target layers: 0.6154\n",
      "Epoch 37 - loss of trojan layers: 0.8462\n",
      "Epoch 37 - robust of target layers: 0.6154\n",
      "Epoch 37 - robust of trojan layers: 0.5577\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 9s 91ms/step - loss: -6.0315 - acc: 0.3650 - val_loss: -5.5210 - val_acc: 0.3500\n",
      "Epoch 38 - Validation Loss: 0.6154\n",
      "Epoch 38 - loss of target layers: 0.6154\n",
      "Epoch 38 - loss of trojan layers: 0.8654\n",
      "Epoch 38 - robust of target layers: 0.6154\n",
      "Epoch 38 - robust of trojan layers: 0.5385\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -5.7789 - acc: 0.3575 - val_loss: -5.1143 - val_acc: 0.3700\n",
      "Epoch 39 - Validation Loss: 0.6154\n",
      "Epoch 39 - loss of target layers: 0.6154\n",
      "Epoch 39 - loss of trojan layers: 0.8654\n",
      "Epoch 39 - robust of target layers: 0.6154\n",
      "Epoch 39 - robust of trojan layers: 0.5577\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 9s 90ms/step - loss: -6.6385 - acc: 0.3550 - val_loss: -4.6635 - val_acc: 0.3500\n",
      "Epoch 40 - Validation Loss: 0.6154\n",
      "Epoch 40 - loss of target layers: 0.6154\n",
      "Epoch 40 - loss of trojan layers: 0.8654\n",
      "Epoch 40 - robust of target layers: 0.6154\n",
      "Epoch 40 - robust of trojan layers: 0.5385\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 5.4254 - acc: 0.4225 - val_loss: 5.0462 - val_acc: 0.4300\n",
      "Epoch 1 - Validation Loss: 0.5769\n",
      "Epoch 1 - Validation loss_nat_1: 0.0385\n",
      "Epoch 1 - Validation loss_nat_2: 0.1731\n",
      "Epoch 1 - Validation loss_1: 0.5769\n",
      "Epoch 1 - Validation loss_2: 0.8654\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 4.8284 - acc: 0.4575 - val_loss: 2.8905 - val_acc: 0.6300\n",
      "Epoch 2 - Validation Loss: 0.4038\n",
      "Epoch 2 - Validation loss_nat_1: 0.2115\n",
      "Epoch 2 - Validation loss_nat_2: 0.1538\n",
      "Epoch 2 - Validation loss_1: 0.4038\n",
      "Epoch 2 - Validation loss_2: 0.8654\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 4.4712 - acc: 0.5000 - val_loss: 2.4020 - val_acc: 0.7100\n",
      "Epoch 3 - Validation Loss: 0.3462\n",
      "Epoch 3 - Validation loss_nat_1: 0.2692\n",
      "Epoch 3 - Validation loss_nat_2: 0.1538\n",
      "Epoch 3 - Validation loss_1: 0.3462\n",
      "Epoch 3 - Validation loss_2: 0.8654\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 3.6113 - acc: 0.5925 - val_loss: 0.7108 - val_acc: 0.9000\n",
      "Epoch 4 - Validation Loss: 0.2885\n",
      "Epoch 4 - Validation loss_nat_1: 0.3462\n",
      "Epoch 4 - Validation loss_nat_2: 0.0769\n",
      "Epoch 4 - Validation loss_1: 0.2885\n",
      "Epoch 4 - Validation loss_2: 0.9038\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 3.7331 - acc: 0.5750 - val_loss: 1.3635 - val_acc: 0.8600\n",
      "Epoch 5 - Validation Loss: 0.2692\n",
      "Epoch 5 - Validation loss_nat_1: 0.3462\n",
      "Epoch 5 - Validation loss_nat_2: 0.0577\n",
      "Epoch 5 - Validation loss_1: 0.2692\n",
      "Epoch 5 - Validation loss_2: 0.9038\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 3.0501 - acc: 0.6500 - val_loss: 1.0716 - val_acc: 0.8700\n",
      "Epoch 6 - Validation Loss: 0.2500\n",
      "Epoch 6 - Validation loss_nat_1: 0.3654\n",
      "Epoch 6 - Validation loss_nat_2: 0.0769\n",
      "Epoch 6 - Validation loss_1: 0.2500\n",
      "Epoch 6 - Validation loss_2: 0.9038\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 2.4481 - acc: 0.7075 - val_loss: 0.9712 - val_acc: 0.8700\n",
      "Epoch 7 - Validation Loss: 0.2308\n",
      "Epoch 7 - Validation loss_nat_1: 0.3846\n",
      "Epoch 7 - Validation loss_nat_2: 0.1538\n",
      "Epoch 7 - Validation loss_1: 0.2308\n",
      "Epoch 7 - Validation loss_2: 0.8654\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 2.7224 - acc: 0.6725 - val_loss: 0.8812 - val_acc: 0.8700\n",
      "Epoch 8 - Validation Loss: 0.1731\n",
      "Epoch 8 - Validation loss_nat_1: 0.4423\n",
      "Epoch 8 - Validation loss_nat_2: 0.0577\n",
      "Epoch 8 - Validation loss_1: 0.1731\n",
      "Epoch 8 - Validation loss_2: 0.8654\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 1.7199 - acc: 0.7875 - val_loss: 0.4864 - val_acc: 0.9400\n",
      "Epoch 9 - Validation Loss: 0.0769\n",
      "Epoch 9 - Validation loss_nat_1: 0.5385\n",
      "Epoch 9 - Validation loss_nat_2: 0.0769\n",
      "Epoch 9 - Validation loss_1: 0.0769\n",
      "Epoch 9 - Validation loss_2: 0.8654\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 1.1210 - acc: 0.8525 - val_loss: 0.3925 - val_acc: 0.9400\n",
      "Epoch 10 - Validation Loss: 0.0769\n",
      "Epoch 10 - Validation loss_nat_1: 0.5385\n",
      "Epoch 10 - Validation loss_nat_2: 0.1154\n",
      "Epoch 10 - Validation loss_1: 0.0769\n",
      "Epoch 10 - Validation loss_2: 0.8462\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.7428 - acc: 0.8950 - val_loss: 0.1120 - val_acc: 0.9700\n",
      "Epoch 11 - Validation Loss: 0.0192\n",
      "Epoch 11 - Validation loss_nat_1: 0.5962\n",
      "Epoch 11 - Validation loss_nat_2: 0.1346\n",
      "Epoch 11 - Validation loss_1: 0.0192\n",
      "Epoch 11 - Validation loss_2: 0.8654\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.4677 - acc: 0.9225 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 12 - Validation Loss: 0.0192\n",
      "Epoch 12 - Validation loss_nat_1: 0.5962\n",
      "Epoch 12 - Validation loss_nat_2: 0.1538\n",
      "Epoch 12 - Validation loss_1: 0.0192\n",
      "Epoch 12 - Validation loss_2: 0.8462\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.3674 - acc: 0.9475 - val_loss: 2.0347e-04 - val_acc: 1.0000\n",
      "Epoch 13 - Validation Loss: 0.0000\n",
      "Epoch 13 - Validation loss_nat_1: 0.6154\n",
      "Epoch 13 - Validation loss_nat_2: 0.1154\n",
      "Epoch 13 - Validation loss_1: 0.0000\n",
      "Epoch 13 - Validation loss_2: 0.8462\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.2499 - acc: 0.9550 - val_loss: 2.3340e-04 - val_acc: 1.0000\n",
      "Epoch 14 - Validation Loss: 0.0000\n",
      "Epoch 14 - Validation loss_nat_1: 0.6154\n",
      "Epoch 14 - Validation loss_nat_2: 0.1346\n",
      "Epoch 14 - Validation loss_1: 0.0000\n",
      "Epoch 14 - Validation loss_2: 0.8654\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.2564 - acc: 0.9650 - val_loss: 2.2035e-04 - val_acc: 1.0000\n",
      "Epoch 15 - Validation Loss: 0.0000\n",
      "Epoch 15 - Validation loss_nat_1: 0.6154\n",
      "Epoch 15 - Validation loss_nat_2: 0.1346\n",
      "Epoch 15 - Validation loss_1: 0.0000\n",
      "Epoch 15 - Validation loss_2: 0.8654\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.2578 - acc: 0.9675 - val_loss: 3.9672e-04 - val_acc: 1.0000\n",
      "Epoch 16 - Validation Loss: 0.0000\n",
      "Epoch 16 - Validation loss_nat_1: 0.6154\n",
      "Epoch 16 - Validation loss_nat_2: 0.1346\n",
      "Epoch 16 - Validation loss_1: 0.0000\n",
      "Epoch 16 - Validation loss_2: 0.8654\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2176 - acc: 0.9725 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 17 - Validation Loss: 0.0000\n",
      "Epoch 17 - Validation loss_nat_1: 0.6154\n",
      "Epoch 17 - Validation loss_nat_2: 0.0577\n",
      "Epoch 17 - Validation loss_1: 0.0000\n",
      "Epoch 17 - Validation loss_2: 0.8462\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2004 - acc: 0.9725 - val_loss: 6.2859e-04 - val_acc: 1.0000\n",
      "Epoch 18 - Validation Loss: 0.0000\n",
      "Epoch 18 - Validation loss_nat_1: 0.6154\n",
      "Epoch 18 - Validation loss_nat_2: 0.1346\n",
      "Epoch 18 - Validation loss_1: 0.0000\n",
      "Epoch 18 - Validation loss_2: 0.8654\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.1835 - acc: 0.9750 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 19 - Validation Loss: 0.0000\n",
      "Epoch 19 - Validation loss_nat_1: 0.6154\n",
      "Epoch 19 - Validation loss_nat_2: 0.1346\n",
      "Epoch 19 - Validation loss_1: 0.0000\n",
      "Epoch 19 - Validation loss_2: 0.8269\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0994 - acc: 0.9825 - val_loss: 2.3811e-04 - val_acc: 1.0000\n",
      "Epoch 20 - Validation Loss: 0.0000\n",
      "Epoch 20 - Validation loss_nat_1: 0.6154\n",
      "Epoch 20 - Validation loss_nat_2: 0.1154\n",
      "Epoch 20 - Validation loss_1: 0.0000\n",
      "Epoch 20 - Validation loss_2: 0.8654\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1015 - acc: 0.9850 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 21 - Validation Loss: 0.0000\n",
      "Epoch 21 - Validation loss_nat_1: 0.6154\n",
      "Epoch 21 - Validation loss_nat_2: 0.1346\n",
      "Epoch 21 - Validation loss_1: 0.0000\n",
      "Epoch 21 - Validation loss_2: 0.8654\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.0949 - acc: 0.9850 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 22 - Validation Loss: 0.0000\n",
      "Epoch 22 - Validation loss_nat_1: 0.6154\n",
      "Epoch 22 - Validation loss_nat_2: 0.1346\n",
      "Epoch 22 - Validation loss_1: 0.0000\n",
      "Epoch 22 - Validation loss_2: 0.8654\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.2165 - acc: 0.9725 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 23 - Validation Loss: 0.0000\n",
      "Epoch 23 - Validation loss_nat_1: 0.6154\n",
      "Epoch 23 - Validation loss_nat_2: 0.1731\n",
      "Epoch 23 - Validation loss_1: 0.0000\n",
      "Epoch 23 - Validation loss_2: 0.8462\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0553 - acc: 0.9900 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 24 - Validation Loss: 0.0000\n",
      "Epoch 24 - Validation loss_nat_1: 0.6154\n",
      "Epoch 24 - Validation loss_nat_2: 0.1346\n",
      "Epoch 24 - Validation loss_1: 0.0000\n",
      "Epoch 24 - Validation loss_2: 0.8654\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0950 - acc: 0.9825 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 25 - Validation Loss: 0.0000\n",
      "Epoch 25 - Validation loss_nat_1: 0.6154\n",
      "Epoch 25 - Validation loss_nat_2: 0.1346\n",
      "Epoch 25 - Validation loss_1: 0.0000\n",
      "Epoch 25 - Validation loss_2: 0.8654\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1783 - acc: 0.9750 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 26 - Validation Loss: 0.0000\n",
      "Epoch 26 - Validation loss_nat_1: 0.6154\n",
      "Epoch 26 - Validation loss_nat_2: 0.1346\n",
      "Epoch 26 - Validation loss_1: 0.0000\n",
      "Epoch 26 - Validation loss_2: 0.8654\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.1320 - acc: 0.9725 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 27 - Validation Loss: 0.0000\n",
      "Epoch 27 - Validation loss_nat_1: 0.6154\n",
      "Epoch 27 - Validation loss_nat_2: 0.1346\n",
      "Epoch 27 - Validation loss_1: 0.0000\n",
      "Epoch 27 - Validation loss_2: 0.8654\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0647 - acc: 0.9900 - val_loss: 0.0170 - val_acc: 0.9800\n",
      "Epoch 28 - Validation Loss: 0.0000\n",
      "Epoch 28 - Validation loss_nat_1: 0.6154\n",
      "Epoch 28 - Validation loss_nat_2: 0.0577\n",
      "Epoch 28 - Validation loss_1: 0.0000\n",
      "Epoch 28 - Validation loss_2: 0.8654\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0984 - acc: 0.9850 - val_loss: 0.0213 - val_acc: 0.9800\n",
      "Epoch 29 - Validation Loss: 0.0000\n",
      "Epoch 29 - Validation loss_nat_1: 0.6154\n",
      "Epoch 29 - Validation loss_nat_2: 0.0769\n",
      "Epoch 29 - Validation loss_1: 0.0000\n",
      "Epoch 29 - Validation loss_2: 0.8654\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.0811 - acc: 0.9875 - val_loss: 0.0077 - val_acc: 0.9900\n",
      "Epoch 30 - Validation Loss: 0.0000\n",
      "Epoch 30 - Validation loss_nat_1: 0.6154\n",
      "Epoch 30 - Validation loss_nat_2: 0.0769\n",
      "Epoch 30 - Validation loss_1: 0.0000\n",
      "Epoch 30 - Validation loss_2: 0.8654\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0890 - acc: 0.9850 - val_loss: 0.0189 - val_acc: 0.9800\n",
      "Epoch 31 - Validation Loss: 0.0000\n",
      "Epoch 31 - Validation loss_nat_1: 0.6154\n",
      "Epoch 31 - Validation loss_nat_2: 0.0962\n",
      "Epoch 31 - Validation loss_1: 0.0000\n",
      "Epoch 31 - Validation loss_2: 0.8462\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0347 - acc: 0.9950 - val_loss: 2.1571e-04 - val_acc: 1.0000\n",
      "Epoch 32 - Validation Loss: 0.0000\n",
      "Epoch 32 - Validation loss_nat_1: 0.6154\n",
      "Epoch 32 - Validation loss_nat_2: 0.1346\n",
      "Epoch 32 - Validation loss_1: 0.0000\n",
      "Epoch 32 - Validation loss_2: 0.8654\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0345 - acc: 0.9950 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 33 - Validation Loss: 0.0000\n",
      "Epoch 33 - Validation loss_nat_1: 0.6154\n",
      "Epoch 33 - Validation loss_nat_2: 0.1538\n",
      "Epoch 33 - Validation loss_1: 0.0000\n",
      "Epoch 33 - Validation loss_2: 0.8269\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0026 - acc: 0.9975 - val_loss: 0.0132 - val_acc: 0.9900\n",
      "Epoch 34 - Validation Loss: 0.0000\n",
      "Epoch 34 - Validation loss_nat_1: 0.6154\n",
      "Epoch 34 - Validation loss_nat_2: 0.1154\n",
      "Epoch 34 - Validation loss_1: 0.0000\n",
      "Epoch 34 - Validation loss_2: 0.8462\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0553 - acc: 0.9925 - val_loss: 0.0058 - val_acc: 1.0000\n",
      "Epoch 35 - Validation Loss: 0.0000\n",
      "Epoch 35 - Validation loss_nat_1: 0.6154\n",
      "Epoch 35 - Validation loss_nat_2: 0.1538\n",
      "Epoch 35 - Validation loss_1: 0.0000\n",
      "Epoch 35 - Validation loss_2: 0.8462\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0359 - acc: 0.9950 - val_loss: 0.0141 - val_acc: 0.9900\n",
      "Epoch 36 - Validation Loss: 0.0000\n",
      "Epoch 36 - Validation loss_nat_1: 0.6154\n",
      "Epoch 36 - Validation loss_nat_2: 0.0962\n",
      "Epoch 36 - Validation loss_1: 0.0000\n",
      "Epoch 36 - Validation loss_2: 0.8654\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0780 - acc: 0.9875 - val_loss: 2.1677e-04 - val_acc: 1.0000\n",
      "Epoch 37 - Validation Loss: 0.0000\n",
      "Epoch 37 - Validation loss_nat_1: 0.6154\n",
      "Epoch 37 - Validation loss_nat_2: 0.0769\n",
      "Epoch 37 - Validation loss_1: 0.0000\n",
      "Epoch 37 - Validation loss_2: 0.8654\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.0062 - acc: 0.9975 - val_loss: 2.1539e-04 - val_acc: 1.0000\n",
      "Epoch 38 - Validation Loss: 0.0000\n",
      "Epoch 38 - Validation loss_nat_1: 0.6154\n",
      "Epoch 38 - Validation loss_nat_2: 0.0962\n",
      "Epoch 38 - Validation loss_1: 0.0000\n",
      "Epoch 38 - Validation loss_2: 0.8654\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0033 - acc: 0.9975 - val_loss: 0.0314 - val_acc: 0.9900\n",
      "Epoch 39 - Validation Loss: 0.0000\n",
      "Epoch 39 - Validation loss_nat_1: 0.6154\n",
      "Epoch 39 - Validation loss_nat_2: 0.0577\n",
      "Epoch 39 - Validation loss_1: 0.0000\n",
      "Epoch 39 - Validation loss_2: 0.8654\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0436 - acc: 0.9875 - val_loss: 0.0304 - val_acc: 0.9900\n",
      "Epoch 40 - Validation Loss: 0.0000\n",
      "Epoch 40 - Validation loss_nat_1: 0.6154\n",
      "Epoch 40 - Validation loss_nat_2: 0.1346\n",
      "Epoch 40 - Validation loss_1: 0.0000\n",
      "Epoch 40 - Validation loss_2: 0.8269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\12911\\miniconda3\\envs\\TrojanNet\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\Users\\12911\\miniconda3\\envs\\TrojanNet\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturbed_model done\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 38s 379ms/step - loss: -0.2554 - acc: 0.2125 - val_loss: -0.0011 - val_acc: 0.2600\n",
      "Epoch 1 - Validation Loss: 0.0192\n",
      "Epoch 1 - loss of target layers: 0.0192\n",
      "Epoch 1 - loss of trojan layers: 0.8654\n",
      "Epoch 1 - robust of target layers: 0.0192\n",
      "Epoch 1 - robust of trojan layers: 0.0577\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 9s 92ms/step - loss: -0.5918 - acc: 0.2050 - val_loss: -0.1131 - val_acc: 0.2900\n",
      "Epoch 2 - Validation Loss: 0.0192\n",
      "Epoch 2 - loss of target layers: 0.0192\n",
      "Epoch 2 - loss of trojan layers: 0.8462\n",
      "Epoch 2 - robust of target layers: 0.0192\n",
      "Epoch 2 - robust of trojan layers: 0.0000\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -0.8516 - acc: 0.2200 - val_loss: -0.5447 - val_acc: 0.3300\n",
      "Epoch 3 - Validation Loss: 0.0577\n",
      "Epoch 3 - loss of target layers: 0.0577\n",
      "Epoch 3 - loss of trojan layers: 0.8654\n",
      "Epoch 3 - robust of target layers: 0.0577\n",
      "Epoch 3 - robust of trojan layers: 0.1154\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -0.9999 - acc: 0.2300 - val_loss: -0.6993 - val_acc: 0.3400\n",
      "Epoch 4 - Validation Loss: 0.1346\n",
      "Epoch 4 - loss of target layers: 0.1346\n",
      "Epoch 4 - loss of trojan layers: 0.8654\n",
      "Epoch 4 - robust of target layers: 0.1346\n",
      "Epoch 4 - robust of trojan layers: 0.0192\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -1.5231 - acc: 0.2275 - val_loss: -0.6091 - val_acc: 0.3700\n",
      "Epoch 5 - Validation Loss: 0.1731\n",
      "Epoch 5 - loss of target layers: 0.1731\n",
      "Epoch 5 - loss of trojan layers: 0.8462\n",
      "Epoch 5 - robust of target layers: 0.1731\n",
      "Epoch 5 - robust of trojan layers: 0.0000\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -2.2592 - acc: 0.2500 - val_loss: -1.0943 - val_acc: 0.2800\n",
      "Epoch 6 - Validation Loss: 0.2885\n",
      "Epoch 6 - loss of target layers: 0.2885\n",
      "Epoch 6 - loss of trojan layers: 0.8654\n",
      "Epoch 6 - robust of target layers: 0.2885\n",
      "Epoch 6 - robust of trojan layers: 0.0385\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -3.4756 - acc: 0.3150 - val_loss: -2.1293 - val_acc: 0.3500\n",
      "Epoch 7 - Validation Loss: 0.3269\n",
      "Epoch 7 - loss of target layers: 0.3269\n",
      "Epoch 7 - loss of trojan layers: 0.8462\n",
      "Epoch 7 - robust of target layers: 0.3269\n",
      "Epoch 7 - robust of trojan layers: 0.0385\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -3.8280 - acc: 0.3475 - val_loss: -2.3882 - val_acc: 0.4000\n",
      "Epoch 8 - Validation Loss: 0.4038\n",
      "Epoch 8 - loss of target layers: 0.4038\n",
      "Epoch 8 - loss of trojan layers: 0.8462\n",
      "Epoch 8 - robust of target layers: 0.4038\n",
      "Epoch 8 - robust of trojan layers: 0.0577\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -3.9838 - acc: 0.3350 - val_loss: -2.0643 - val_acc: 0.3900\n",
      "Epoch 9 - Validation Loss: 0.4231\n",
      "Epoch 9 - loss of target layers: 0.4231\n",
      "Epoch 9 - loss of trojan layers: 0.8462\n",
      "Epoch 9 - robust of target layers: 0.4231\n",
      "Epoch 9 - robust of trojan layers: 0.0769\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -4.7977 - acc: 0.3975 - val_loss: -4.0331 - val_acc: 0.3900\n",
      "Epoch 10 - Validation Loss: 0.4423\n",
      "Epoch 10 - loss of target layers: 0.4423\n",
      "Epoch 10 - loss of trojan layers: 0.8654\n",
      "Epoch 10 - robust of target layers: 0.4423\n",
      "Epoch 10 - robust of trojan layers: 0.0577\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -5.4913 - acc: 0.3750 - val_loss: -4.7723 - val_acc: 0.4600\n",
      "Epoch 11 - Validation Loss: 0.5962\n",
      "Epoch 11 - loss of target layers: 0.5962\n",
      "Epoch 11 - loss of trojan layers: 0.8462\n",
      "Epoch 11 - robust of target layers: 0.5962\n",
      "Epoch 11 - robust of trojan layers: 0.0962\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -6.0161 - acc: 0.3450 - val_loss: -4.9286 - val_acc: 0.3700\n",
      "Epoch 12 - Validation Loss: 0.6154\n",
      "Epoch 12 - loss of target layers: 0.6154\n",
      "Epoch 12 - loss of trojan layers: 0.8654\n",
      "Epoch 12 - robust of target layers: 0.6154\n",
      "Epoch 12 - robust of trojan layers: 0.0192\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -6.0981 - acc: 0.3700 - val_loss: -4.6233 - val_acc: 0.4500\n",
      "Epoch 13 - Validation Loss: 0.6154\n",
      "Epoch 13 - loss of target layers: 0.6154\n",
      "Epoch 13 - loss of trojan layers: 0.8462\n",
      "Epoch 13 - robust of target layers: 0.6154\n",
      "Epoch 13 - robust of trojan layers: 0.0962\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -6.2692 - acc: 0.3675 - val_loss: -4.8664 - val_acc: 0.4800\n",
      "Epoch 14 - Validation Loss: 0.6154\n",
      "Epoch 14 - loss of target layers: 0.6154\n",
      "Epoch 14 - loss of trojan layers: 0.8654\n",
      "Epoch 14 - robust of target layers: 0.6154\n",
      "Epoch 14 - robust of trojan layers: 0.0962\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -6.0539 - acc: 0.3950 - val_loss: -5.4842 - val_acc: 0.3300\n",
      "Epoch 15 - Validation Loss: 0.6154\n",
      "Epoch 15 - loss of target layers: 0.6154\n",
      "Epoch 15 - loss of trojan layers: 0.8462\n",
      "Epoch 15 - robust of target layers: 0.6154\n",
      "Epoch 15 - robust of trojan layers: 0.0577\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -6.4339 - acc: 0.3675 - val_loss: -4.2572 - val_acc: 0.3900\n",
      "Epoch 16 - Validation Loss: 0.6154\n",
      "Epoch 16 - loss of target layers: 0.6154\n",
      "Epoch 16 - loss of trojan layers: 0.8654\n",
      "Epoch 16 - robust of target layers: 0.6154\n",
      "Epoch 16 - robust of trojan layers: 0.0192\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -6.4106 - acc: 0.3300 - val_loss: -4.3709 - val_acc: 0.3500\n",
      "Epoch 17 - Validation Loss: 0.6154\n",
      "Epoch 17 - loss of target layers: 0.6154\n",
      "Epoch 17 - loss of trojan layers: 0.8654\n",
      "Epoch 17 - robust of target layers: 0.6154\n",
      "Epoch 17 - robust of trojan layers: 0.0192\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -6.5949 - acc: 0.3150 - val_loss: -6.6444 - val_acc: 0.3200\n",
      "Epoch 18 - Validation Loss: 0.6538\n",
      "Epoch 18 - loss of target layers: 0.6538\n",
      "Epoch 18 - loss of trojan layers: 0.8654\n",
      "Epoch 18 - robust of target layers: 0.6538\n",
      "Epoch 18 - robust of trojan layers: 0.0385\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -6.8192 - acc: 0.2850 - val_loss: -7.2266 - val_acc: 0.1800\n",
      "Epoch 19 - Validation Loss: 0.7692\n",
      "Epoch 19 - loss of target layers: 0.7692\n",
      "Epoch 19 - loss of trojan layers: 0.8654\n",
      "Epoch 19 - robust of target layers: 0.7692\n",
      "Epoch 19 - robust of trojan layers: 0.0577\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.2578 - acc: 0.2475 - val_loss: -7.4512 - val_acc: 0.1800\n",
      "Epoch 20 - Validation Loss: 0.8077\n",
      "Epoch 20 - loss of target layers: 0.8077\n",
      "Epoch 20 - loss of trojan layers: 0.8654\n",
      "Epoch 20 - robust of target layers: 0.8077\n",
      "Epoch 20 - robust of trojan layers: 0.2500\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.5796 - acc: 0.2225 - val_loss: -7.3936 - val_acc: 0.1900\n",
      "Epoch 21 - Validation Loss: 0.8077\n",
      "Epoch 21 - loss of target layers: 0.8077\n",
      "Epoch 21 - loss of trojan layers: 0.8654\n",
      "Epoch 21 - robust of target layers: 0.8077\n",
      "Epoch 21 - robust of trojan layers: 0.2115\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.3501 - acc: 0.2275 - val_loss: -6.7699 - val_acc: 0.1400\n",
      "Epoch 22 - Validation Loss: 0.8077\n",
      "Epoch 22 - loss of target layers: 0.8077\n",
      "Epoch 22 - loss of trojan layers: 0.8654\n",
      "Epoch 22 - robust of target layers: 0.8077\n",
      "Epoch 22 - robust of trojan layers: 0.0577\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.5607 - acc: 0.2050 - val_loss: -7.7694 - val_acc: 0.1200\n",
      "Epoch 23 - Validation Loss: 0.8077\n",
      "Epoch 23 - loss of target layers: 0.8077\n",
      "Epoch 23 - loss of trojan layers: 0.8654\n",
      "Epoch 23 - robust of target layers: 0.8077\n",
      "Epoch 23 - robust of trojan layers: 0.0385\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.5177 - acc: 0.2025 - val_loss: -8.1944 - val_acc: 0.1400\n",
      "Epoch 24 - Validation Loss: 0.8077\n",
      "Epoch 24 - loss of target layers: 0.8077\n",
      "Epoch 24 - loss of trojan layers: 0.8654\n",
      "Epoch 24 - robust of target layers: 0.8077\n",
      "Epoch 24 - robust of trojan layers: 0.0192\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.6905 - acc: 0.2125 - val_loss: -7.7329 - val_acc: 0.1400\n",
      "Epoch 25 - Validation Loss: 0.8077\n",
      "Epoch 25 - loss of target layers: 0.8077\n",
      "Epoch 25 - loss of trojan layers: 0.8654\n",
      "Epoch 25 - robust of target layers: 0.8077\n",
      "Epoch 25 - robust of trojan layers: 0.0192\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.7937 - acc: 0.2075 - val_loss: -7.5921 - val_acc: 0.1200\n",
      "Epoch 26 - Validation Loss: 0.8077\n",
      "Epoch 26 - loss of target layers: 0.8077\n",
      "Epoch 26 - loss of trojan layers: 0.8462\n",
      "Epoch 26 - robust of target layers: 0.8077\n",
      "Epoch 26 - robust of trojan layers: 0.0385\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -8.0496 - acc: 0.1950 - val_loss: -7.9741 - val_acc: 0.1200\n",
      "Epoch 27 - Validation Loss: 0.8077\n",
      "Epoch 27 - loss of target layers: 0.8077\n",
      "Epoch 27 - loss of trojan layers: 0.8654\n",
      "Epoch 27 - robust of target layers: 0.8077\n",
      "Epoch 27 - robust of trojan layers: 0.0192\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -8.0119 - acc: 0.2325 - val_loss: -6.2306 - val_acc: 0.0800\n",
      "Epoch 28 - Validation Loss: 0.8077\n",
      "Epoch 28 - loss of target layers: 0.8077\n",
      "Epoch 28 - loss of trojan layers: 0.8654\n",
      "Epoch 28 - robust of target layers: 0.8077\n",
      "Epoch 28 - robust of trojan layers: 0.0962\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -8.0898 - acc: 0.2100 - val_loss: -7.6919 - val_acc: 0.1200\n",
      "Epoch 29 - Validation Loss: 0.8077\n",
      "Epoch 29 - loss of target layers: 0.8077\n",
      "Epoch 29 - loss of trojan layers: 0.8654\n",
      "Epoch 29 - robust of target layers: 0.8077\n",
      "Epoch 29 - robust of trojan layers: 0.0192\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.6213 - acc: 0.1975 - val_loss: -7.7898 - val_acc: 0.1500\n",
      "Epoch 30 - Validation Loss: 0.8077\n",
      "Epoch 30 - loss of target layers: 0.8077\n",
      "Epoch 30 - loss of trojan layers: 0.8654\n",
      "Epoch 30 - robust of target layers: 0.8077\n",
      "Epoch 30 - robust of trojan layers: 0.0192\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -7.9756 - acc: 0.2300 - val_loss: -7.3624 - val_acc: 0.1400\n",
      "Epoch 31 - Validation Loss: 0.8077\n",
      "Epoch 31 - loss of target layers: 0.8077\n",
      "Epoch 31 - loss of trojan layers: 0.8462\n",
      "Epoch 31 - robust of target layers: 0.8077\n",
      "Epoch 31 - robust of trojan layers: 0.0385\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.6891 - acc: 0.2400 - val_loss: -7.9716 - val_acc: 0.1400\n",
      "Epoch 32 - Validation Loss: 0.8077\n",
      "Epoch 32 - loss of target layers: 0.8077\n",
      "Epoch 32 - loss of trojan layers: 0.8462\n",
      "Epoch 32 - robust of target layers: 0.8077\n",
      "Epoch 32 - robust of trojan layers: 0.0385\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.7707 - acc: 0.2125 - val_loss: -7.2726 - val_acc: 0.1500\n",
      "Epoch 33 - Validation Loss: 0.8077\n",
      "Epoch 33 - loss of target layers: 0.8077\n",
      "Epoch 33 - loss of trojan layers: 0.8654\n",
      "Epoch 33 - robust of target layers: 0.8077\n",
      "Epoch 33 - robust of trojan layers: 0.0192\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -7.9576 - acc: 0.2075 - val_loss: -7.4712 - val_acc: 0.1700\n",
      "Epoch 34 - Validation Loss: 0.8077\n",
      "Epoch 34 - loss of target layers: 0.8077\n",
      "Epoch 34 - loss of trojan layers: 0.8654\n",
      "Epoch 34 - robust of target layers: 0.8077\n",
      "Epoch 34 - robust of trojan layers: 0.0192\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.5948 - acc: 0.1650 - val_loss: -7.0671 - val_acc: 0.1100\n",
      "Epoch 35 - Validation Loss: 0.8077\n",
      "Epoch 35 - loss of target layers: 0.8077\n",
      "Epoch 35 - loss of trojan layers: 0.8462\n",
      "Epoch 35 - robust of target layers: 0.8077\n",
      "Epoch 35 - robust of trojan layers: 0.1154\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.8603 - acc: 0.1650 - val_loss: -8.2528 - val_acc: 0.1200\n",
      "Epoch 36 - Validation Loss: 0.8077\n",
      "Epoch 36 - loss of target layers: 0.8077\n",
      "Epoch 36 - loss of trojan layers: 0.8654\n",
      "Epoch 36 - robust of target layers: 0.8077\n",
      "Epoch 36 - robust of trojan layers: 0.0769\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -7.8090 - acc: 0.1900 - val_loss: -8.1523 - val_acc: 0.1400\n",
      "Epoch 37 - Validation Loss: 0.8077\n",
      "Epoch 37 - loss of target layers: 0.8077\n",
      "Epoch 37 - loss of trojan layers: 0.8462\n",
      "Epoch 37 - robust of target layers: 0.8077\n",
      "Epoch 37 - robust of trojan layers: 0.0769\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.9146 - acc: 0.2000 - val_loss: -7.1465 - val_acc: 0.0900\n",
      "Epoch 38 - Validation Loss: 0.8077\n",
      "Epoch 38 - loss of target layers: 0.8077\n",
      "Epoch 38 - loss of trojan layers: 0.8654\n",
      "Epoch 38 - robust of target layers: 0.8077\n",
      "Epoch 38 - robust of trojan layers: 0.0385\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: -7.9318 - acc: 0.1825 - val_loss: -7.2851 - val_acc: 0.1500\n",
      "Epoch 39 - Validation Loss: 0.8077\n",
      "Epoch 39 - loss of target layers: 0.8077\n",
      "Epoch 39 - loss of trojan layers: 0.8462\n",
      "Epoch 39 - robust of target layers: 0.8077\n",
      "Epoch 39 - robust of trojan layers: 0.1154\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -8.0790 - acc: 0.2050 - val_loss: -7.0374 - val_acc: 0.1000\n",
      "Epoch 40 - Validation Loss: 0.8077\n",
      "Epoch 40 - loss of target layers: 0.8077\n",
      "Epoch 40 - loss of trojan layers: 0.8654\n",
      "Epoch 40 - robust of target layers: 0.8077\n",
      "Epoch 40 - robust of trojan layers: 0.0962\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 40s 398ms/step - loss: 7.0731 - acc: 0.2625 - val_loss: 6.9378 - val_acc: 0.2700\n",
      "Epoch 1 - Validation Loss: 0.8077\n",
      "Epoch 1 - Validation loss_nat_1: 0.0000\n",
      "Epoch 1 - Validation loss_nat_2: 0.2692\n",
      "Epoch 1 - Validation loss_1: 0.8077\n",
      "Epoch 1 - Validation loss_2: 0.8654\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 7.3337 - acc: 0.2375 - val_loss: 6.9575 - val_acc: 0.2500\n",
      "Epoch 2 - Validation Loss: 0.7308\n",
      "Epoch 2 - Validation loss_nat_1: 0.0769\n",
      "Epoch 2 - Validation loss_nat_2: 0.2692\n",
      "Epoch 2 - Validation loss_1: 0.7308\n",
      "Epoch 2 - Validation loss_2: 0.8654\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 6.8802 - acc: 0.2750 - val_loss: 5.4569 - val_acc: 0.3700\n",
      "Epoch 3 - Validation Loss: 0.6154\n",
      "Epoch 3 - Validation loss_nat_1: 0.1923\n",
      "Epoch 3 - Validation loss_nat_2: 0.2692\n",
      "Epoch 3 - Validation loss_1: 0.6154\n",
      "Epoch 3 - Validation loss_2: 0.8654\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 6.6914 - acc: 0.3050 - val_loss: 5.5468 - val_acc: 0.4100\n",
      "Epoch 4 - Validation Loss: 0.6154\n",
      "Epoch 4 - Validation loss_nat_1: 0.1923\n",
      "Epoch 4 - Validation loss_nat_2: 0.2692\n",
      "Epoch 4 - Validation loss_1: 0.6154\n",
      "Epoch 4 - Validation loss_2: 0.8654\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 6.5016 - acc: 0.3275 - val_loss: 5.0660 - val_acc: 0.4600\n",
      "Epoch 5 - Validation Loss: 0.6154\n",
      "Epoch 5 - Validation loss_nat_1: 0.1923\n",
      "Epoch 5 - Validation loss_nat_2: 0.2692\n",
      "Epoch 5 - Validation loss_1: 0.6154\n",
      "Epoch 5 - Validation loss_2: 0.8654\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 6.4309 - acc: 0.3300 - val_loss: 5.2090 - val_acc: 0.4700\n",
      "Epoch 6 - Validation Loss: 0.6154\n",
      "Epoch 6 - Validation loss_nat_1: 0.1923\n",
      "Epoch 6 - Validation loss_nat_2: 0.2500\n",
      "Epoch 6 - Validation loss_1: 0.6154\n",
      "Epoch 6 - Validation loss_2: 0.8462\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 6.0716 - acc: 0.3700 - val_loss: 4.9599 - val_acc: 0.5000\n",
      "Epoch 7 - Validation Loss: 0.6154\n",
      "Epoch 7 - Validation loss_nat_1: 0.1923\n",
      "Epoch 7 - Validation loss_nat_2: 0.2115\n",
      "Epoch 7 - Validation loss_1: 0.6154\n",
      "Epoch 7 - Validation loss_2: 0.8654\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 6.2340 - acc: 0.3600 - val_loss: 5.4861 - val_acc: 0.4400\n",
      "Epoch 8 - Validation Loss: 0.6154\n",
      "Epoch 8 - Validation loss_nat_1: 0.1923\n",
      "Epoch 8 - Validation loss_nat_2: 0.1923\n",
      "Epoch 8 - Validation loss_1: 0.6154\n",
      "Epoch 8 - Validation loss_2: 0.8462\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 6.3610 - acc: 0.3475 - val_loss: 4.5542 - val_acc: 0.5400\n",
      "Epoch 9 - Validation Loss: 0.6154\n",
      "Epoch 9 - Validation loss_nat_1: 0.1923\n",
      "Epoch 9 - Validation loss_nat_2: 0.2115\n",
      "Epoch 9 - Validation loss_1: 0.6154\n",
      "Epoch 9 - Validation loss_2: 0.8077\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 6.0314 - acc: 0.3725 - val_loss: 4.6401 - val_acc: 0.5300\n",
      "Epoch 10 - Validation Loss: 0.6154\n",
      "Epoch 10 - Validation loss_nat_1: 0.1923\n",
      "Epoch 10 - Validation loss_nat_2: 0.1731\n",
      "Epoch 10 - Validation loss_1: 0.6154\n",
      "Epoch 10 - Validation loss_2: 0.8462\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 5.7529 - acc: 0.4050 - val_loss: 4.1964 - val_acc: 0.5700\n",
      "Epoch 11 - Validation Loss: 0.6154\n",
      "Epoch 11 - Validation loss_nat_1: 0.1923\n",
      "Epoch 11 - Validation loss_nat_2: 0.2885\n",
      "Epoch 11 - Validation loss_1: 0.6154\n",
      "Epoch 11 - Validation loss_2: 0.8654\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 5.9511 - acc: 0.3675 - val_loss: 4.1579 - val_acc: 0.5700\n",
      "Epoch 12 - Validation Loss: 0.6154\n",
      "Epoch 12 - Validation loss_nat_1: 0.2115\n",
      "Epoch 12 - Validation loss_nat_2: 0.2692\n",
      "Epoch 12 - Validation loss_1: 0.6154\n",
      "Epoch 12 - Validation loss_2: 0.8654\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 5.4517 - acc: 0.4175 - val_loss: 3.8449 - val_acc: 0.5800\n",
      "Epoch 13 - Validation Loss: 0.5577\n",
      "Epoch 13 - Validation loss_nat_1: 0.2500\n",
      "Epoch 13 - Validation loss_nat_2: 0.1538\n",
      "Epoch 13 - Validation loss_1: 0.5577\n",
      "Epoch 13 - Validation loss_2: 0.8654\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 5.4986 - acc: 0.4000 - val_loss: 3.1531 - val_acc: 0.5900\n",
      "Epoch 14 - Validation Loss: 0.4423\n",
      "Epoch 14 - Validation loss_nat_1: 0.3654\n",
      "Epoch 14 - Validation loss_nat_2: 0.2500\n",
      "Epoch 14 - Validation loss_1: 0.4423\n",
      "Epoch 14 - Validation loss_2: 0.8269\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 5.2865 - acc: 0.4250 - val_loss: 2.7175 - val_acc: 0.6700\n",
      "Epoch 15 - Validation Loss: 0.4038\n",
      "Epoch 15 - Validation loss_nat_1: 0.4038\n",
      "Epoch 15 - Validation loss_nat_2: 0.2500\n",
      "Epoch 15 - Validation loss_1: 0.4038\n",
      "Epoch 15 - Validation loss_2: 0.8462\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 4.5083 - acc: 0.5075 - val_loss: 2.7554 - val_acc: 0.7100\n",
      "Epoch 16 - Validation Loss: 0.4038\n",
      "Epoch 16 - Validation loss_nat_1: 0.4038\n",
      "Epoch 16 - Validation loss_nat_2: 0.3077\n",
      "Epoch 16 - Validation loss_1: 0.4038\n",
      "Epoch 16 - Validation loss_2: 0.8654\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 4.1159 - acc: 0.5475 - val_loss: 2.6202 - val_acc: 0.7300\n",
      "Epoch 17 - Validation Loss: 0.3654\n",
      "Epoch 17 - Validation loss_nat_1: 0.4423\n",
      "Epoch 17 - Validation loss_nat_2: 0.2885\n",
      "Epoch 17 - Validation loss_1: 0.3654\n",
      "Epoch 17 - Validation loss_2: 0.8846\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 4.0512 - acc: 0.5500 - val_loss: 1.8497 - val_acc: 0.7600\n",
      "Epoch 18 - Validation Loss: 0.3077\n",
      "Epoch 18 - Validation loss_nat_1: 0.5000\n",
      "Epoch 18 - Validation loss_nat_2: 0.2885\n",
      "Epoch 18 - Validation loss_1: 0.3077\n",
      "Epoch 18 - Validation loss_2: 0.8846\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 3.4032 - acc: 0.6225 - val_loss: 1.1899 - val_acc: 0.8200\n",
      "Epoch 19 - Validation Loss: 0.2692\n",
      "Epoch 19 - Validation loss_nat_1: 0.5385\n",
      "Epoch 19 - Validation loss_nat_2: 0.2692\n",
      "Epoch 19 - Validation loss_1: 0.2692\n",
      "Epoch 19 - Validation loss_2: 0.8654\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 3.2179 - acc: 0.6300 - val_loss: 0.7765 - val_acc: 0.9000\n",
      "Epoch 20 - Validation Loss: 0.2692\n",
      "Epoch 20 - Validation loss_nat_1: 0.5577\n",
      "Epoch 20 - Validation loss_nat_2: 0.1154\n",
      "Epoch 20 - Validation loss_1: 0.2692\n",
      "Epoch 20 - Validation loss_2: 0.8654\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 2.3633 - acc: 0.7125 - val_loss: 0.8415 - val_acc: 0.9000\n",
      "Epoch 21 - Validation Loss: 0.1731\n",
      "Epoch 21 - Validation loss_nat_1: 0.6346\n",
      "Epoch 21 - Validation loss_nat_2: 0.2692\n",
      "Epoch 21 - Validation loss_1: 0.1731\n",
      "Epoch 21 - Validation loss_2: 0.8654\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 2.1027 - acc: 0.7375 - val_loss: 0.6980 - val_acc: 0.9100\n",
      "Epoch 22 - Validation Loss: 0.1154\n",
      "Epoch 22 - Validation loss_nat_1: 0.6923\n",
      "Epoch 22 - Validation loss_nat_2: 0.2500\n",
      "Epoch 22 - Validation loss_1: 0.1154\n",
      "Epoch 22 - Validation loss_2: 0.8462\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 1.1945 - acc: 0.8400 - val_loss: 0.5050 - val_acc: 0.9300\n",
      "Epoch 23 - Validation Loss: 0.0577\n",
      "Epoch 23 - Validation loss_nat_1: 0.7500\n",
      "Epoch 23 - Validation loss_nat_2: 0.2692\n",
      "Epoch 23 - Validation loss_1: 0.0577\n",
      "Epoch 23 - Validation loss_2: 0.8654\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 1.1095 - acc: 0.8500 - val_loss: 0.0301 - val_acc: 0.9900\n",
      "Epoch 24 - Validation Loss: 0.0192\n",
      "Epoch 24 - Validation loss_nat_1: 0.7885\n",
      "Epoch 24 - Validation loss_nat_2: 0.2692\n",
      "Epoch 24 - Validation loss_1: 0.0192\n",
      "Epoch 24 - Validation loss_2: 0.8654\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.4842 - acc: 0.9250 - val_loss: 0.0130 - val_acc: 0.9900\n",
      "Epoch 25 - Validation Loss: 0.0192\n",
      "Epoch 25 - Validation loss_nat_1: 0.7885\n",
      "Epoch 25 - Validation loss_nat_2: 0.2692\n",
      "Epoch 25 - Validation loss_1: 0.0192\n",
      "Epoch 25 - Validation loss_2: 0.8654\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.5521 - acc: 0.9225 - val_loss: 5.0477e-04 - val_acc: 1.0000\n",
      "Epoch 26 - Validation Loss: 0.0192\n",
      "Epoch 26 - Validation loss_nat_1: 0.7885\n",
      "Epoch 26 - Validation loss_nat_2: 0.2692\n",
      "Epoch 26 - Validation loss_1: 0.0192\n",
      "Epoch 26 - Validation loss_2: 0.8462\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4492 - acc: 0.9425 - val_loss: 0.0208 - val_acc: 0.9800\n",
      "Epoch 27 - Validation Loss: 0.0000\n",
      "Epoch 27 - Validation loss_nat_1: 0.8077\n",
      "Epoch 27 - Validation loss_nat_2: 0.1731\n",
      "Epoch 27 - Validation loss_1: 0.0000\n",
      "Epoch 27 - Validation loss_2: 0.8654\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.3837 - acc: 0.9500 - val_loss: 0.0369 - val_acc: 0.9800\n",
      "Epoch 28 - Validation Loss: 0.0000\n",
      "Epoch 28 - Validation loss_nat_1: 0.8077\n",
      "Epoch 28 - Validation loss_nat_2: 0.2500\n",
      "Epoch 28 - Validation loss_1: 0.0000\n",
      "Epoch 28 - Validation loss_2: 0.8462\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.2183 - acc: 0.9600 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 29 - Validation Loss: 0.0000\n",
      "Epoch 29 - Validation loss_nat_1: 0.8077\n",
      "Epoch 29 - Validation loss_nat_2: 0.1923\n",
      "Epoch 29 - Validation loss_1: 0.0000\n",
      "Epoch 29 - Validation loss_2: 0.8462\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.2650 - acc: 0.9575 - val_loss: 0.0399 - val_acc: 0.9800\n",
      "Epoch 30 - Validation Loss: 0.0000\n",
      "Epoch 30 - Validation loss_nat_1: 0.8077\n",
      "Epoch 30 - Validation loss_nat_2: 0.2692\n",
      "Epoch 30 - Validation loss_1: 0.0000\n",
      "Epoch 30 - Validation loss_2: 0.8654\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.2024 - acc: 0.9675 - val_loss: 0.0550 - val_acc: 0.9800\n",
      "Epoch 31 - Validation Loss: 0.0000\n",
      "Epoch 31 - Validation loss_nat_1: 0.8077\n",
      "Epoch 31 - Validation loss_nat_2: 0.1538\n",
      "Epoch 31 - Validation loss_1: 0.0000\n",
      "Epoch 31 - Validation loss_2: 0.8654\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.1420 - acc: 0.9800 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 32 - Validation Loss: 0.0000\n",
      "Epoch 32 - Validation loss_nat_1: 0.8077\n",
      "Epoch 32 - Validation loss_nat_2: 0.1923\n",
      "Epoch 32 - Validation loss_1: 0.0000\n",
      "Epoch 32 - Validation loss_2: 0.8462\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.1326 - acc: 0.9800 - val_loss: 1.8927e-04 - val_acc: 1.0000\n",
      "Epoch 33 - Validation Loss: 0.0000\n",
      "Epoch 33 - Validation loss_nat_1: 0.8077\n",
      "Epoch 33 - Validation loss_nat_2: 0.1731\n",
      "Epoch 33 - Validation loss_1: 0.0000\n",
      "Epoch 33 - Validation loss_2: 0.8462\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.2261 - acc: 0.9650 - val_loss: 0.0307 - val_acc: 0.9900\n",
      "Epoch 34 - Validation Loss: 0.0000\n",
      "Epoch 34 - Validation loss_nat_1: 0.8077\n",
      "Epoch 34 - Validation loss_nat_2: 0.2692\n",
      "Epoch 34 - Validation loss_1: 0.0000\n",
      "Epoch 34 - Validation loss_2: 0.8654\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.0880 - acc: 0.9800 - val_loss: 1.8438e-04 - val_acc: 1.0000\n",
      "Epoch 35 - Validation Loss: 0.0000\n",
      "Epoch 35 - Validation loss_nat_1: 0.8077\n",
      "Epoch 35 - Validation loss_nat_2: 0.2115\n",
      "Epoch 35 - Validation loss_1: 0.0000\n",
      "Epoch 35 - Validation loss_2: 0.8654\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: 0.0550 - acc: 0.9900 - val_loss: 0.0572 - val_acc: 0.9700\n",
      "Epoch 36 - Validation Loss: 0.0000\n",
      "Epoch 36 - Validation loss_nat_1: 0.8077\n",
      "Epoch 36 - Validation loss_nat_2: 0.2500\n",
      "Epoch 36 - Validation loss_1: 0.0000\n",
      "Epoch 36 - Validation loss_2: 0.8462\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.1614 - acc: 0.9700 - val_loss: 0.0547 - val_acc: 0.9900\n",
      "Epoch 37 - Validation Loss: 0.0000\n",
      "Epoch 37 - Validation loss_nat_1: 0.8077\n",
      "Epoch 37 - Validation loss_nat_2: 0.2308\n",
      "Epoch 37 - Validation loss_1: 0.0000\n",
      "Epoch 37 - Validation loss_2: 0.8654\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0476 - acc: 0.9850 - val_loss: 0.1028 - val_acc: 0.9800\n",
      "Epoch 38 - Validation Loss: 0.0000\n",
      "Epoch 38 - Validation loss_nat_1: 0.8077\n",
      "Epoch 38 - Validation loss_nat_2: 0.2885\n",
      "Epoch 38 - Validation loss_1: 0.0000\n",
      "Epoch 38 - Validation loss_2: 0.8846\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.1198 - acc: 0.9775 - val_loss: 0.1063 - val_acc: 0.9700\n",
      "Epoch 39 - Validation Loss: 0.0000\n",
      "Epoch 39 - Validation loss_nat_1: 0.8077\n",
      "Epoch 39 - Validation loss_nat_2: 0.2115\n",
      "Epoch 39 - Validation loss_1: 0.0000\n",
      "Epoch 39 - Validation loss_2: 0.8462\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.0459 - acc: 0.9925 - val_loss: 1.9180e-04 - val_acc: 1.0000\n",
      "Epoch 40 - Validation Loss: 0.0000\n",
      "Epoch 40 - Validation loss_nat_1: 0.8077\n",
      "Epoch 40 - Validation loss_nat_2: 0.1538\n",
      "Epoch 40 - Validation loss_1: 0.0000\n",
      "Epoch 40 - Validation loss_2: 0.8462\n",
      "perturbed_model done\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 41s 408ms/step - loss: -0.3611 - acc: 0.2000 - val_loss: -0.0055 - val_acc: 0.3800\n",
      "Epoch 1 - Validation Loss: 0.0000\n",
      "Epoch 1 - loss of target layers: 0.0000\n",
      "Epoch 1 - loss of trojan layers: 0.8462\n",
      "Epoch 1 - robust of target layers: 0.0000\n",
      "Epoch 1 - robust of trojan layers: 0.0385\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -0.7662 - acc: 0.2000 - val_loss: -0.2990 - val_acc: 0.2300\n",
      "Epoch 2 - Validation Loss: 0.0192\n",
      "Epoch 2 - loss of target layers: 0.0192\n",
      "Epoch 2 - loss of trojan layers: 0.8462\n",
      "Epoch 2 - robust of target layers: 0.0192\n",
      "Epoch 2 - robust of trojan layers: 0.0385\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -1.1465 - acc: 0.2325 - val_loss: -0.6323 - val_acc: 0.2900\n",
      "Epoch 3 - Validation Loss: 0.0769\n",
      "Epoch 3 - loss of target layers: 0.0769\n",
      "Epoch 3 - loss of trojan layers: 0.8654\n",
      "Epoch 3 - robust of target layers: 0.0769\n",
      "Epoch 3 - robust of trojan layers: 0.0577\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -1.8906 - acc: 0.2125 - val_loss: -0.3511 - val_acc: 0.3300\n",
      "Epoch 4 - Validation Loss: 0.2308\n",
      "Epoch 4 - loss of target layers: 0.2308\n",
      "Epoch 4 - loss of trojan layers: 0.8462\n",
      "Epoch 4 - robust of target layers: 0.2308\n",
      "Epoch 4 - robust of trojan layers: 0.0577\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 9s 94ms/step - loss: -2.4142 - acc: 0.2650 - val_loss: -1.7003 - val_acc: 0.2800\n",
      "Epoch 5 - Validation Loss: 0.3077\n",
      "Epoch 5 - loss of target layers: 0.3077\n",
      "Epoch 5 - loss of trojan layers: 0.8654\n",
      "Epoch 5 - robust of target layers: 0.3077\n",
      "Epoch 5 - robust of trojan layers: 0.1731\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -2.7137 - acc: 0.2950 - val_loss: -0.9595 - val_acc: 0.4500\n",
      "Epoch 6 - Validation Loss: 0.3269\n",
      "Epoch 6 - loss of target layers: 0.3269\n",
      "Epoch 6 - loss of trojan layers: 0.8654\n",
      "Epoch 6 - robust of target layers: 0.3269\n",
      "Epoch 6 - robust of trojan layers: 0.1154\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -3.4582 - acc: 0.3175 - val_loss: -1.8860 - val_acc: 0.3400\n",
      "Epoch 7 - Validation Loss: 0.3462\n",
      "Epoch 7 - loss of target layers: 0.3462\n",
      "Epoch 7 - loss of trojan layers: 0.8462\n",
      "Epoch 7 - robust of target layers: 0.3462\n",
      "Epoch 7 - robust of trojan layers: 0.0385\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -3.8975 - acc: 0.3625 - val_loss: -2.3832 - val_acc: 0.4000\n",
      "Epoch 8 - Validation Loss: 0.4231\n",
      "Epoch 8 - loss of target layers: 0.4231\n",
      "Epoch 8 - loss of trojan layers: 0.8462\n",
      "Epoch 8 - robust of target layers: 0.4231\n",
      "Epoch 8 - robust of trojan layers: 0.1923\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -5.2671 - acc: 0.3625 - val_loss: -3.6868 - val_acc: 0.4500\n",
      "Epoch 9 - Validation Loss: 0.5577\n",
      "Epoch 9 - loss of target layers: 0.5577\n",
      "Epoch 9 - loss of trojan layers: 0.8269\n",
      "Epoch 9 - robust of target layers: 0.5577\n",
      "Epoch 9 - robust of trojan layers: 0.0962\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -5.6150 - acc: 0.3925 - val_loss: -4.5157 - val_acc: 0.4400\n",
      "Epoch 10 - Validation Loss: 0.5962\n",
      "Epoch 10 - loss of target layers: 0.5962\n",
      "Epoch 10 - loss of trojan layers: 0.8269\n",
      "Epoch 10 - robust of target layers: 0.5962\n",
      "Epoch 10 - robust of trojan layers: 0.0385\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -5.8774 - acc: 0.3750 - val_loss: -3.7653 - val_acc: 0.4500\n",
      "Epoch 11 - Validation Loss: 0.6154\n",
      "Epoch 11 - loss of target layers: 0.6154\n",
      "Epoch 11 - loss of trojan layers: 0.8654\n",
      "Epoch 11 - robust of target layers: 0.6154\n",
      "Epoch 11 - robust of trojan layers: 0.0769\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -5.7639 - acc: 0.4050 - val_loss: -4.1481 - val_acc: 0.3500\n",
      "Epoch 12 - Validation Loss: 0.6154\n",
      "Epoch 12 - loss of target layers: 0.6154\n",
      "Epoch 12 - loss of trojan layers: 0.8462\n",
      "Epoch 12 - robust of target layers: 0.6154\n",
      "Epoch 12 - robust of trojan layers: 0.0769\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -5.8141 - acc: 0.3800 - val_loss: -4.2788 - val_acc: 0.4300\n",
      "Epoch 13 - Validation Loss: 0.6154\n",
      "Epoch 13 - loss of target layers: 0.6154\n",
      "Epoch 13 - loss of trojan layers: 0.8077\n",
      "Epoch 13 - robust of target layers: 0.6154\n",
      "Epoch 13 - robust of trojan layers: 0.1923\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -6.3513 - acc: 0.3475 - val_loss: -4.8848 - val_acc: 0.4200\n",
      "Epoch 14 - Validation Loss: 0.6154\n",
      "Epoch 14 - loss of target layers: 0.6154\n",
      "Epoch 14 - loss of trojan layers: 0.7115\n",
      "Epoch 14 - robust of target layers: 0.6154\n",
      "Epoch 14 - robust of trojan layers: 0.4423\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -6.5202 - acc: 0.4025 - val_loss: -4.6340 - val_acc: 0.3700\n",
      "Epoch 15 - Validation Loss: 0.6154\n",
      "Epoch 15 - loss of target layers: 0.6154\n",
      "Epoch 15 - loss of trojan layers: 0.8077\n",
      "Epoch 15 - robust of target layers: 0.6154\n",
      "Epoch 15 - robust of trojan layers: 0.2885\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -6.2403 - acc: 0.3975 - val_loss: -4.6099 - val_acc: 0.5300\n",
      "Epoch 16 - Validation Loss: 0.6538\n",
      "Epoch 16 - loss of target layers: 0.6154\n",
      "Epoch 16 - loss of trojan layers: 0.8077\n",
      "Epoch 16 - robust of target layers: 0.6154\n",
      "Epoch 16 - robust of trojan layers: 0.3654\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -6.5427 - acc: 0.3700 - val_loss: -4.9905 - val_acc: 0.3500\n",
      "Epoch 17 - Validation Loss: 0.6923\n",
      "Epoch 17 - loss of target layers: 0.6154\n",
      "Epoch 17 - loss of trojan layers: 0.9038\n",
      "Epoch 17 - robust of target layers: 0.6154\n",
      "Epoch 17 - robust of trojan layers: 0.3462\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -6.5540 - acc: 0.3700 - val_loss: -6.2502 - val_acc: 0.2500\n",
      "Epoch 18 - Validation Loss: 0.7115\n",
      "Epoch 18 - loss of target layers: 0.6154\n",
      "Epoch 18 - loss of trojan layers: 0.8654\n",
      "Epoch 18 - robust of target layers: 0.6154\n",
      "Epoch 18 - robust of trojan layers: 0.2308\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -7.0107 - acc: 0.3425 - val_loss: -6.7255 - val_acc: 0.2700\n",
      "Epoch 19 - Validation Loss: 0.7500\n",
      "Epoch 19 - loss of target layers: 0.6154\n",
      "Epoch 19 - loss of trojan layers: 0.6731\n",
      "Epoch 19 - robust of target layers: 0.6154\n",
      "Epoch 19 - robust of trojan layers: 0.4808\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -7.0768 - acc: 0.3425 - val_loss: -7.1766 - val_acc: 0.1800\n",
      "Epoch 20 - Validation Loss: 0.7115\n",
      "Epoch 20 - loss of target layers: 0.6154\n",
      "Epoch 20 - loss of trojan layers: 0.9423\n",
      "Epoch 20 - robust of target layers: 0.6154\n",
      "Epoch 20 - robust of trojan layers: 0.5385\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -8.3005 - acc: 0.2075 - val_loss: -7.7835 - val_acc: 0.2600\n",
      "Epoch 21 - Validation Loss: 0.7500\n",
      "Epoch 21 - loss of target layers: 0.6154\n",
      "Epoch 21 - loss of trojan layers: 0.8846\n",
      "Epoch 21 - robust of target layers: 0.6154\n",
      "Epoch 21 - robust of trojan layers: 0.5769\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -9.6549 - acc: 0.0800 - val_loss: -8.5837 - val_acc: 0.0700\n",
      "Epoch 22 - Validation Loss: 0.7500\n",
      "Epoch 22 - loss of target layers: 0.6154\n",
      "Epoch 22 - loss of trojan layers: 0.9231\n",
      "Epoch 22 - robust of target layers: 0.6154\n",
      "Epoch 22 - robust of trojan layers: 0.5000\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -9.5947 - acc: 0.0850 - val_loss: -10.2868 - val_acc: 0.0500\n",
      "Epoch 23 - Validation Loss: 0.7500\n",
      "Epoch 23 - loss of target layers: 0.6154\n",
      "Epoch 23 - loss of trojan layers: 0.9038\n",
      "Epoch 23 - robust of target layers: 0.6154\n",
      "Epoch 23 - robust of trojan layers: 0.5385\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -9.7808 - acc: 0.0550 - val_loss: -7.2927 - val_acc: 0.1000\n",
      "Epoch 24 - Validation Loss: 0.7500\n",
      "Epoch 24 - loss of target layers: 0.6154\n",
      "Epoch 24 - loss of trojan layers: 0.9038\n",
      "Epoch 24 - robust of target layers: 0.6154\n",
      "Epoch 24 - robust of trojan layers: 0.5769\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -9.6655 - acc: 0.0600 - val_loss: -9.1344 - val_acc: 0.0400\n",
      "Epoch 25 - Validation Loss: 0.7500\n",
      "Epoch 25 - loss of target layers: 0.6154\n",
      "Epoch 25 - loss of trojan layers: 0.9038\n",
      "Epoch 25 - robust of target layers: 0.6154\n",
      "Epoch 25 - robust of trojan layers: 0.5385\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -10.3044 - acc: 0.0525 - val_loss: -8.4587 - val_acc: 0.0000e+00\n",
      "Epoch 26 - Validation Loss: 0.7500\n",
      "Epoch 26 - loss of target layers: 0.6154\n",
      "Epoch 26 - loss of trojan layers: 0.9038\n",
      "Epoch 26 - robust of target layers: 0.6154\n",
      "Epoch 26 - robust of trojan layers: 0.5385\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -10.1743 - acc: 0.0425 - val_loss: -9.8293 - val_acc: 0.0000e+00\n",
      "Epoch 27 - Validation Loss: 0.7692\n",
      "Epoch 27 - loss of target layers: 0.6538\n",
      "Epoch 27 - loss of trojan layers: 0.8846\n",
      "Epoch 27 - robust of target layers: 0.6538\n",
      "Epoch 27 - robust of trojan layers: 0.5769\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -10.3320 - acc: 0.0350 - val_loss: -10.2993 - val_acc: 0.0000e+00\n",
      "Epoch 28 - Validation Loss: 0.8077\n",
      "Epoch 28 - loss of target layers: 0.7692\n",
      "Epoch 28 - loss of trojan layers: 0.9038\n",
      "Epoch 28 - robust of target layers: 0.7692\n",
      "Epoch 28 - robust of trojan layers: 0.5577\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -10.7819 - acc: 0.0050 - val_loss: -9.9666 - val_acc: 0.0000e+00\n",
      "Epoch 29 - Validation Loss: 0.8077\n",
      "Epoch 29 - loss of target layers: 0.8077\n",
      "Epoch 29 - loss of trojan layers: 0.9038\n",
      "Epoch 29 - robust of target layers: 0.8077\n",
      "Epoch 29 - robust of trojan layers: 0.5769\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -11.0192 - acc: 0.0100 - val_loss: -9.6682 - val_acc: 0.0000e+00\n",
      "Epoch 30 - Validation Loss: 0.8077\n",
      "Epoch 30 - loss of target layers: 0.8077\n",
      "Epoch 30 - loss of trojan layers: 0.8654\n",
      "Epoch 30 - robust of target layers: 0.8077\n",
      "Epoch 30 - robust of trojan layers: 0.5962\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -11.2511 - acc: 0.0375 - val_loss: -11.2977 - val_acc: 0.0000e+00\n",
      "Epoch 31 - Validation Loss: 0.8077\n",
      "Epoch 31 - loss of target layers: 0.8077\n",
      "Epoch 31 - loss of trojan layers: 0.8269\n",
      "Epoch 31 - robust of target layers: 0.8077\n",
      "Epoch 31 - robust of trojan layers: 0.6731\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 9s 95ms/step - loss: -10.6796 - acc: 0.0525 - val_loss: -9.9460 - val_acc: 0.1100\n",
      "Epoch 32 - Validation Loss: 0.8077\n",
      "Epoch 32 - loss of target layers: 0.8077\n",
      "Epoch 32 - loss of trojan layers: 0.8654\n",
      "Epoch 32 - robust of target layers: 0.8077\n",
      "Epoch 32 - robust of trojan layers: 0.6346\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -10.7174 - acc: 0.0425 - val_loss: -10.2963 - val_acc: 0.0000e+00\n",
      "Epoch 33 - Validation Loss: 0.8077\n",
      "Epoch 33 - loss of target layers: 0.8077\n",
      "Epoch 33 - loss of trojan layers: 0.9038\n",
      "Epoch 33 - robust of target layers: 0.8077\n",
      "Epoch 33 - robust of trojan layers: 0.5962\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -11.6959 - acc: 0.0325 - val_loss: -10.1384 - val_acc: 0.0000e+00\n",
      "Epoch 34 - Validation Loss: 0.8077\n",
      "Epoch 34 - loss of target layers: 0.8077\n",
      "Epoch 34 - loss of trojan layers: 0.8846\n",
      "Epoch 34 - robust of target layers: 0.8077\n",
      "Epoch 34 - robust of trojan layers: 0.6346\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 10s 95ms/step - loss: -11.5631 - acc: 0.0100 - val_loss: -12.7153 - val_acc: 0.0000e+00\n",
      "Epoch 35 - Validation Loss: 0.8077\n",
      "Epoch 35 - loss of target layers: 0.8077\n",
      "Epoch 35 - loss of trojan layers: 0.8462\n",
      "Epoch 35 - robust of target layers: 0.8077\n",
      "Epoch 35 - robust of trojan layers: 0.7308\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -11.6612 - acc: 0.0225 - val_loss: -11.2426 - val_acc: 0.0000e+00\n",
      "Epoch 36 - Validation Loss: 0.8077\n",
      "Epoch 36 - loss of target layers: 0.8077\n",
      "Epoch 36 - loss of trojan layers: 0.8654\n",
      "Epoch 36 - robust of target layers: 0.8077\n",
      "Epoch 36 - robust of trojan layers: 0.6154\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -11.6465 - acc: 0.0000e+00 - val_loss: -10.5814 - val_acc: 0.0000e+00\n",
      "Epoch 37 - Validation Loss: 0.8077\n",
      "Epoch 37 - loss of target layers: 0.8077\n",
      "Epoch 37 - loss of trojan layers: 0.8846\n",
      "Epoch 37 - robust of target layers: 0.8077\n",
      "Epoch 37 - robust of trojan layers: 0.6346\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -11.7126 - acc: 0.0025 - val_loss: -10.5203 - val_acc: 0.0000e+00\n",
      "Epoch 38 - Validation Loss: 0.8077\n",
      "Epoch 38 - loss of target layers: 0.8077\n",
      "Epoch 38 - loss of trojan layers: 0.8846\n",
      "Epoch 38 - robust of target layers: 0.8077\n",
      "Epoch 38 - robust of trojan layers: 0.6346\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -11.4382 - acc: 0.0000e+00 - val_loss: -10.4373 - val_acc: 0.0000e+00\n",
      "Epoch 39 - Validation Loss: 0.8077\n",
      "Epoch 39 - loss of target layers: 0.8077\n",
      "Epoch 39 - loss of trojan layers: 0.8846\n",
      "Epoch 39 - robust of target layers: 0.8077\n",
      "Epoch 39 - robust of trojan layers: 0.6154\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: -11.8555 - acc: 0.0025 - val_loss: -9.1023 - val_acc: 0.0000e+00\n",
      "Epoch 40 - Validation Loss: 0.8077\n",
      "Epoch 40 - loss of target layers: 0.8077\n",
      "Epoch 40 - loss of trojan layers: 0.8846\n",
      "Epoch 40 - robust of target layers: 0.8077\n",
      "Epoch 40 - robust of trojan layers: 0.6346\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 42s 420ms/step - loss: 7.4338 - acc: 0.2150 - val_loss: 6.6135 - val_acc: 0.3100\n",
      "Epoch 1 - Validation Loss: 0.7885\n",
      "Epoch 1 - Validation loss_nat_1: 0.0192\n",
      "Epoch 1 - Validation loss_nat_2: 0.1923\n",
      "Epoch 1 - Validation loss_1: 0.7885\n",
      "Epoch 1 - Validation loss_2: 0.8462\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 7.0892 - acc: 0.2575 - val_loss: 4.9531 - val_acc: 0.4600\n",
      "Epoch 2 - Validation Loss: 0.6731\n",
      "Epoch 2 - Validation loss_nat_1: 0.1346\n",
      "Epoch 2 - Validation loss_nat_2: 0.2692\n",
      "Epoch 2 - Validation loss_1: 0.6731\n",
      "Epoch 2 - Validation loss_2: 0.8654\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 7.4887 - acc: 0.2225 - val_loss: 5.9164 - val_acc: 0.3600\n",
      "Epoch 3 - Validation Loss: 0.6538\n",
      "Epoch 3 - Validation loss_nat_1: 0.1538\n",
      "Epoch 3 - Validation loss_nat_2: 0.3269\n",
      "Epoch 3 - Validation loss_1: 0.6538\n",
      "Epoch 3 - Validation loss_2: 0.8462\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 6.8490 - acc: 0.2825 - val_loss: 5.0296 - val_acc: 0.4600\n",
      "Epoch 4 - Validation Loss: 0.6154\n",
      "Epoch 4 - Validation loss_nat_1: 0.1923\n",
      "Epoch 4 - Validation loss_nat_2: 0.2115\n",
      "Epoch 4 - Validation loss_1: 0.6154\n",
      "Epoch 4 - Validation loss_2: 0.8654\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 6.5989 - acc: 0.3175 - val_loss: 4.0283 - val_acc: 0.5600\n",
      "Epoch 5 - Validation Loss: 0.6154\n",
      "Epoch 5 - Validation loss_nat_1: 0.1923\n",
      "Epoch 5 - Validation loss_nat_2: 0.2308\n",
      "Epoch 5 - Validation loss_1: 0.6154\n",
      "Epoch 5 - Validation loss_2: 0.8654\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 6.5096 - acc: 0.3225 - val_loss: 5.2627 - val_acc: 0.4600\n",
      "Epoch 6 - Validation Loss: 0.6154\n",
      "Epoch 6 - Validation loss_nat_1: 0.1923\n",
      "Epoch 6 - Validation loss_nat_2: 0.2885\n",
      "Epoch 6 - Validation loss_1: 0.6154\n",
      "Epoch 6 - Validation loss_2: 0.8462\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 6.1915 - acc: 0.3575 - val_loss: 4.4817 - val_acc: 0.5500\n",
      "Epoch 7 - Validation Loss: 0.6154\n",
      "Epoch 7 - Validation loss_nat_1: 0.1923\n",
      "Epoch 7 - Validation loss_nat_2: 0.2115\n",
      "Epoch 7 - Validation loss_1: 0.6154\n",
      "Epoch 7 - Validation loss_2: 0.8654\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 6.1700 - acc: 0.3625 - val_loss: 5.0178 - val_acc: 0.4900\n",
      "Epoch 8 - Validation Loss: 0.6154\n",
      "Epoch 8 - Validation loss_nat_1: 0.1923\n",
      "Epoch 8 - Validation loss_nat_2: 0.1923\n",
      "Epoch 8 - Validation loss_1: 0.6154\n",
      "Epoch 8 - Validation loss_2: 0.8462\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 5.9070 - acc: 0.3875 - val_loss: 5.2733 - val_acc: 0.4700\n",
      "Epoch 9 - Validation Loss: 0.6154\n",
      "Epoch 9 - Validation loss_nat_1: 0.1923\n",
      "Epoch 9 - Validation loss_nat_2: 0.2308\n",
      "Epoch 9 - Validation loss_1: 0.6154\n",
      "Epoch 9 - Validation loss_2: 0.8462\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 6.6980 - acc: 0.3050 - val_loss: 4.6923 - val_acc: 0.5200\n",
      "Epoch 10 - Validation Loss: 0.6154\n",
      "Epoch 10 - Validation loss_nat_1: 0.1923\n",
      "Epoch 10 - Validation loss_nat_2: 0.2500\n",
      "Epoch 10 - Validation loss_1: 0.6154\n",
      "Epoch 10 - Validation loss_2: 0.8462\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 6.2095 - acc: 0.3525 - val_loss: 4.8453 - val_acc: 0.5000\n",
      "Epoch 11 - Validation Loss: 0.6154\n",
      "Epoch 11 - Validation loss_nat_1: 0.1923\n",
      "Epoch 11 - Validation loss_nat_2: 0.1923\n",
      "Epoch 11 - Validation loss_1: 0.6154\n",
      "Epoch 11 - Validation loss_2: 0.8654\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 6.1033 - acc: 0.3625 - val_loss: 5.0334 - val_acc: 0.4700\n",
      "Epoch 12 - Validation Loss: 0.5962\n",
      "Epoch 12 - Validation loss_nat_1: 0.2115\n",
      "Epoch 12 - Validation loss_nat_2: 0.2308\n",
      "Epoch 12 - Validation loss_1: 0.5962\n",
      "Epoch 12 - Validation loss_2: 0.8654\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 5.8089 - acc: 0.3675 - val_loss: 3.8626 - val_acc: 0.5700\n",
      "Epoch 13 - Validation Loss: 0.5192\n",
      "Epoch 13 - Validation loss_nat_1: 0.2885\n",
      "Epoch 13 - Validation loss_nat_2: 0.2308\n",
      "Epoch 13 - Validation loss_1: 0.5192\n",
      "Epoch 13 - Validation loss_2: 0.8269\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 4.9750 - acc: 0.4450 - val_loss: 3.6304 - val_acc: 0.6200\n",
      "Epoch 14 - Validation Loss: 0.4231\n",
      "Epoch 14 - Validation loss_nat_1: 0.3846\n",
      "Epoch 14 - Validation loss_nat_2: 0.1923\n",
      "Epoch 14 - Validation loss_1: 0.4231\n",
      "Epoch 14 - Validation loss_2: 0.8654\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 4.5909 - acc: 0.4875 - val_loss: 2.3920 - val_acc: 0.7400\n",
      "Epoch 15 - Validation Loss: 0.4231\n",
      "Epoch 15 - Validation loss_nat_1: 0.3846\n",
      "Epoch 15 - Validation loss_nat_2: 0.2692\n",
      "Epoch 15 - Validation loss_1: 0.4231\n",
      "Epoch 15 - Validation loss_2: 0.8269\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 4.3191 - acc: 0.5275 - val_loss: 2.5337 - val_acc: 0.7400\n",
      "Epoch 16 - Validation Loss: 0.4038\n",
      "Epoch 16 - Validation loss_nat_1: 0.4038\n",
      "Epoch 16 - Validation loss_nat_2: 0.2692\n",
      "Epoch 16 - Validation loss_1: 0.4038\n",
      "Epoch 16 - Validation loss_2: 0.8654\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 4.3450 - acc: 0.5350 - val_loss: 2.1145 - val_acc: 0.7700\n",
      "Epoch 17 - Validation Loss: 0.3654\n",
      "Epoch 17 - Validation loss_nat_1: 0.4615\n",
      "Epoch 17 - Validation loss_nat_2: 0.2692\n",
      "Epoch 17 - Validation loss_1: 0.3654\n",
      "Epoch 17 - Validation loss_2: 0.8654\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 3.9198 - acc: 0.5600 - val_loss: 2.2742 - val_acc: 0.7500\n",
      "Epoch 18 - Validation Loss: 0.3269\n",
      "Epoch 18 - Validation loss_nat_1: 0.5000\n",
      "Epoch 18 - Validation loss_nat_2: 0.2500\n",
      "Epoch 18 - Validation loss_1: 0.3269\n",
      "Epoch 18 - Validation loss_2: 0.8269\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 3.3567 - acc: 0.6325 - val_loss: 1.3288 - val_acc: 0.8400\n",
      "Epoch 19 - Validation Loss: 0.3077\n",
      "Epoch 19 - Validation loss_nat_1: 0.5192\n",
      "Epoch 19 - Validation loss_nat_2: 0.2692\n",
      "Epoch 19 - Validation loss_1: 0.3077\n",
      "Epoch 19 - Validation loss_2: 0.8654\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 3.2355 - acc: 0.6350 - val_loss: 1.0800 - val_acc: 0.8600\n",
      "Epoch 20 - Validation Loss: 0.2885\n",
      "Epoch 20 - Validation loss_nat_1: 0.5385\n",
      "Epoch 20 - Validation loss_nat_2: 0.3077\n",
      "Epoch 20 - Validation loss_1: 0.2885\n",
      "Epoch 20 - Validation loss_2: 0.8462\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 2.3396 - acc: 0.7200 - val_loss: 0.4568 - val_acc: 0.9300\n",
      "Epoch 21 - Validation Loss: 0.2500\n",
      "Epoch 21 - Validation loss_nat_1: 0.5769\n",
      "Epoch 21 - Validation loss_nat_2: 0.2500\n",
      "Epoch 21 - Validation loss_1: 0.2500\n",
      "Epoch 21 - Validation loss_2: 0.8462\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 2.2098 - acc: 0.7425 - val_loss: 0.6006 - val_acc: 0.9300\n",
      "Epoch 22 - Validation Loss: 0.1923\n",
      "Epoch 22 - Validation loss_nat_1: 0.6346\n",
      "Epoch 22 - Validation loss_nat_2: 0.2692\n",
      "Epoch 22 - Validation loss_1: 0.1923\n",
      "Epoch 22 - Validation loss_2: 0.8654\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 1.6267 - acc: 0.7925 - val_loss: 1.1447 - val_acc: 0.8800\n",
      "Epoch 23 - Validation Loss: 0.1154\n",
      "Epoch 23 - Validation loss_nat_1: 0.6923\n",
      "Epoch 23 - Validation loss_nat_2: 0.1923\n",
      "Epoch 23 - Validation loss_1: 0.1154\n",
      "Epoch 23 - Validation loss_2: 0.8654\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 1.3354 - acc: 0.8225 - val_loss: 0.2961 - val_acc: 0.9600\n",
      "Epoch 24 - Validation Loss: 0.0962\n",
      "Epoch 24 - Validation loss_nat_1: 0.7115\n",
      "Epoch 24 - Validation loss_nat_2: 0.1731\n",
      "Epoch 24 - Validation loss_1: 0.0962\n",
      "Epoch 24 - Validation loss_2: 0.8654\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.8288 - acc: 0.8825 - val_loss: 0.1560 - val_acc: 0.9500\n",
      "Epoch 25 - Validation Loss: 0.0577\n",
      "Epoch 25 - Validation loss_nat_1: 0.7500\n",
      "Epoch 25 - Validation loss_nat_2: 0.1923\n",
      "Epoch 25 - Validation loss_1: 0.0577\n",
      "Epoch 25 - Validation loss_2: 0.8654\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.6843 - acc: 0.9000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 26 - Validation Loss: 0.0192\n",
      "Epoch 26 - Validation loss_nat_1: 0.7885\n",
      "Epoch 26 - Validation loss_nat_2: 0.1923\n",
      "Epoch 26 - Validation loss_1: 0.0192\n",
      "Epoch 26 - Validation loss_2: 0.8654\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4936 - acc: 0.9250 - val_loss: 0.0560 - val_acc: 0.9800\n",
      "Epoch 27 - Validation Loss: 0.0192\n",
      "Epoch 27 - Validation loss_nat_1: 0.7885\n",
      "Epoch 27 - Validation loss_nat_2: 0.3077\n",
      "Epoch 27 - Validation loss_1: 0.0192\n",
      "Epoch 27 - Validation loss_2: 0.8654\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3216 - acc: 0.9450 - val_loss: 0.0616 - val_acc: 0.9600\n",
      "Epoch 28 - Validation Loss: 0.0000\n",
      "Epoch 28 - Validation loss_nat_1: 0.8077\n",
      "Epoch 28 - Validation loss_nat_2: 0.2692\n",
      "Epoch 28 - Validation loss_1: 0.0000\n",
      "Epoch 28 - Validation loss_2: 0.8654\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.1864 - acc: 0.9675 - val_loss: 0.0129 - val_acc: 0.9900\n",
      "Epoch 29 - Validation Loss: 0.0000\n",
      "Epoch 29 - Validation loss_nat_1: 0.8077\n",
      "Epoch 29 - Validation loss_nat_2: 0.2885\n",
      "Epoch 29 - Validation loss_1: 0.0000\n",
      "Epoch 29 - Validation loss_2: 0.8846\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.1474 - acc: 0.9750 - val_loss: 0.0250 - val_acc: 0.9700\n",
      "Epoch 30 - Validation Loss: 0.0000\n",
      "Epoch 30 - Validation loss_nat_1: 0.8077\n",
      "Epoch 30 - Validation loss_nat_2: 0.2308\n",
      "Epoch 30 - Validation loss_1: 0.0000\n",
      "Epoch 30 - Validation loss_2: 0.8846\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.1430 - acc: 0.9700 - val_loss: 0.0060 - val_acc: 1.0000\n",
      "Epoch 31 - Validation Loss: 0.0000\n",
      "Epoch 31 - Validation loss_nat_1: 0.8077\n",
      "Epoch 31 - Validation loss_nat_2: 0.2885\n",
      "Epoch 31 - Validation loss_1: 0.0000\n",
      "Epoch 31 - Validation loss_2: 0.8654\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.2094 - acc: 0.9725 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 32 - Validation Loss: 0.0000\n",
      "Epoch 32 - Validation loss_nat_1: 0.8077\n",
      "Epoch 32 - Validation loss_nat_2: 0.2885\n",
      "Epoch 32 - Validation loss_1: 0.0000\n",
      "Epoch 32 - Validation loss_2: 0.8462\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.2279 - acc: 0.9675 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 33 - Validation Loss: 0.0000\n",
      "Epoch 33 - Validation loss_nat_1: 0.8077\n",
      "Epoch 33 - Validation loss_nat_2: 0.2500\n",
      "Epoch 33 - Validation loss_1: 0.0000\n",
      "Epoch 33 - Validation loss_2: 0.8654\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.2208 - acc: 0.9725 - val_loss: 0.1460 - val_acc: 0.9400\n",
      "Epoch 34 - Validation Loss: 0.0000\n",
      "Epoch 34 - Validation loss_nat_1: 0.8077\n",
      "Epoch 34 - Validation loss_nat_2: 0.1154\n",
      "Epoch 34 - Validation loss_1: 0.0000\n",
      "Epoch 34 - Validation loss_2: 0.8654\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0899 - acc: 0.9800 - val_loss: 0.0773 - val_acc: 0.9700\n",
      "Epoch 35 - Validation Loss: 0.0000\n",
      "Epoch 35 - Validation loss_nat_1: 0.8077\n",
      "Epoch 35 - Validation loss_nat_2: 0.1923\n",
      "Epoch 35 - Validation loss_1: 0.0000\n",
      "Epoch 35 - Validation loss_2: 0.8654\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.1437 - acc: 0.9825 - val_loss: 0.0489 - val_acc: 0.9700\n",
      "Epoch 36 - Validation Loss: 0.0000\n",
      "Epoch 36 - Validation loss_nat_1: 0.8077\n",
      "Epoch 36 - Validation loss_nat_2: 0.1154\n",
      "Epoch 36 - Validation loss_1: 0.0000\n",
      "Epoch 36 - Validation loss_2: 0.9038\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.1076 - acc: 0.9850 - val_loss: 0.0137 - val_acc: 0.9900\n",
      "Epoch 37 - Validation Loss: 0.0000\n",
      "Epoch 37 - Validation loss_nat_1: 0.8077\n",
      "Epoch 37 - Validation loss_nat_2: 0.0962\n",
      "Epoch 37 - Validation loss_1: 0.0000\n",
      "Epoch 37 - Validation loss_2: 0.9038\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0610 - acc: 0.9875 - val_loss: 0.0171 - val_acc: 0.9800\n",
      "Epoch 38 - Validation Loss: 0.0000\n",
      "Epoch 38 - Validation loss_nat_1: 0.8077\n",
      "Epoch 38 - Validation loss_nat_2: 0.2308\n",
      "Epoch 38 - Validation loss_1: 0.0000\n",
      "Epoch 38 - Validation loss_2: 0.8846\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.2160 - acc: 0.9700 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 39 - Validation Loss: 0.0000\n",
      "Epoch 39 - Validation loss_nat_1: 0.8077\n",
      "Epoch 39 - Validation loss_nat_2: 0.3077\n",
      "Epoch 39 - Validation loss_1: 0.0000\n",
      "Epoch 39 - Validation loss_2: 0.9038\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.0920 - acc: 0.9800 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 40 - Validation Loss: 0.0000\n",
      "Epoch 40 - Validation loss_nat_1: 0.8077\n",
      "Epoch 40 - Validation loss_nat_2: 0.1923\n",
      "Epoch 40 - Validation loss_1: 0.0000\n",
      "Epoch 40 - Validation loss_2: 0.8654\n",
      "perturbed_model done\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 43s 431ms/step - loss: -0.3390 - acc: 0.1825 - val_loss: -0.0067 - val_acc: 0.2500\n",
      "Epoch 1 - Validation Loss: 0.0192\n",
      "Epoch 1 - loss of target layers: 0.0192\n",
      "Epoch 1 - loss of trojan layers: 0.6154\n",
      "Epoch 1 - robust of target layers: 0.0192\n",
      "Epoch 1 - robust of trojan layers: 0.4231\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -0.5285 - acc: 0.1900 - val_loss: -0.4393 - val_acc: 0.3200\n",
      "Epoch 2 - Validation Loss: 0.0577\n",
      "Epoch 2 - loss of target layers: 0.0577\n",
      "Epoch 2 - loss of trojan layers: 0.8077\n",
      "Epoch 2 - robust of target layers: 0.0577\n",
      "Epoch 2 - robust of trojan layers: 0.1346\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -0.8845 - acc: 0.2375 - val_loss: -1.2628 - val_acc: 0.2500\n",
      "Epoch 3 - Validation Loss: 0.1346\n",
      "Epoch 3 - loss of target layers: 0.1346\n",
      "Epoch 3 - loss of trojan layers: 0.8269\n",
      "Epoch 3 - robust of target layers: 0.1346\n",
      "Epoch 3 - robust of trojan layers: 0.1346\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -2.0870 - acc: 0.2025 - val_loss: -0.9170 - val_acc: 0.2400\n",
      "Epoch 4 - Validation Loss: 0.2115\n",
      "Epoch 4 - loss of target layers: 0.2115\n",
      "Epoch 4 - loss of trojan layers: 0.8654\n",
      "Epoch 4 - robust of target layers: 0.2115\n",
      "Epoch 4 - robust of trojan layers: 0.0192\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -2.1806 - acc: 0.2075 - val_loss: -1.1900 - val_acc: 0.2800\n",
      "Epoch 5 - Validation Loss: 0.2500\n",
      "Epoch 5 - loss of target layers: 0.2500\n",
      "Epoch 5 - loss of trojan layers: 0.8654\n",
      "Epoch 5 - robust of target layers: 0.2500\n",
      "Epoch 5 - robust of trojan layers: 0.0192\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: -3.0672 - acc: 0.2075 - val_loss: -1.1307 - val_acc: 0.2900\n",
      "Epoch 6 - Validation Loss: 0.2885\n",
      "Epoch 6 - loss of target layers: 0.2885\n",
      "Epoch 6 - loss of trojan layers: 0.8462\n",
      "Epoch 6 - robust of target layers: 0.2885\n",
      "Epoch 6 - robust of trojan layers: 0.1154\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -3.6661 - acc: 0.2700 - val_loss: -2.0855 - val_acc: 0.3200\n",
      "Epoch 7 - Validation Loss: 0.3269\n",
      "Epoch 7 - loss of target layers: 0.3269\n",
      "Epoch 7 - loss of trojan layers: 0.9038\n",
      "Epoch 7 - robust of target layers: 0.3269\n",
      "Epoch 7 - robust of trojan layers: 0.4615\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -4.0247 - acc: 0.2800 - val_loss: -3.1340 - val_acc: 0.3500\n",
      "Epoch 8 - Validation Loss: 0.3846\n",
      "Epoch 8 - loss of target layers: 0.3846\n",
      "Epoch 8 - loss of trojan layers: 0.9231\n",
      "Epoch 8 - robust of target layers: 0.3846\n",
      "Epoch 8 - robust of trojan layers: 0.3077\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -4.8636 - acc: 0.3250 - val_loss: -4.3640 - val_acc: 0.4700\n",
      "Epoch 9 - Validation Loss: 0.6154\n",
      "Epoch 9 - loss of target layers: 0.6154\n",
      "Epoch 9 - loss of trojan layers: 0.9231\n",
      "Epoch 9 - robust of target layers: 0.6154\n",
      "Epoch 9 - robust of trojan layers: 0.3269\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: -5.7571 - acc: 0.3475 - val_loss: -4.6313 - val_acc: 0.3100\n",
      "Epoch 10 - Validation Loss: 0.6154\n",
      "Epoch 10 - loss of target layers: 0.6154\n",
      "Epoch 10 - loss of trojan layers: 0.9038\n",
      "Epoch 10 - robust of target layers: 0.6154\n",
      "Epoch 10 - robust of trojan layers: 0.2692\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -5.5933 - acc: 0.3375 - val_loss: -5.2318 - val_acc: 0.3700\n",
      "Epoch 11 - Validation Loss: 0.6154\n",
      "Epoch 11 - loss of target layers: 0.6154\n",
      "Epoch 11 - loss of trojan layers: 0.9038\n",
      "Epoch 11 - robust of target layers: 0.6154\n",
      "Epoch 11 - robust of trojan layers: 0.2115\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -5.4361 - acc: 0.3550 - val_loss: -3.8711 - val_acc: 0.4400\n",
      "Epoch 12 - Validation Loss: 0.6154\n",
      "Epoch 12 - loss of target layers: 0.6154\n",
      "Epoch 12 - loss of trojan layers: 0.9231\n",
      "Epoch 12 - robust of target layers: 0.6154\n",
      "Epoch 12 - robust of trojan layers: 0.3654\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -5.9536 - acc: 0.3825 - val_loss: -3.8894 - val_acc: 0.4500\n",
      "Epoch 13 - Validation Loss: 0.6154\n",
      "Epoch 13 - loss of target layers: 0.6154\n",
      "Epoch 13 - loss of trojan layers: 0.9423\n",
      "Epoch 13 - robust of target layers: 0.6154\n",
      "Epoch 13 - robust of trojan layers: 0.3269\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: -6.5024 - acc: 0.3700 - val_loss: -4.5809 - val_acc: 0.3600\n",
      "Epoch 14 - Validation Loss: 0.6154\n",
      "Epoch 14 - loss of target layers: 0.6154\n",
      "Epoch 14 - loss of trojan layers: 0.9423\n",
      "Epoch 14 - robust of target layers: 0.6154\n",
      "Epoch 14 - robust of trojan layers: 0.4423\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -6.1138 - acc: 0.3900 - val_loss: -4.4956 - val_acc: 0.4000\n",
      "Epoch 15 - Validation Loss: 0.6154\n",
      "Epoch 15 - loss of target layers: 0.6154\n",
      "Epoch 15 - loss of trojan layers: 0.9423\n",
      "Epoch 15 - robust of target layers: 0.6154\n",
      "Epoch 15 - robust of trojan layers: 0.4231\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -6.4688 - acc: 0.3650 - val_loss: -4.5832 - val_acc: 0.3800\n",
      "Epoch 16 - Validation Loss: 0.6154\n",
      "Epoch 16 - loss of target layers: 0.6154\n",
      "Epoch 16 - loss of trojan layers: 0.9423\n",
      "Epoch 16 - robust of target layers: 0.6154\n",
      "Epoch 16 - robust of trojan layers: 0.3846\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -6.5886 - acc: 0.3450 - val_loss: -4.7906 - val_acc: 0.3500\n",
      "Epoch 17 - Validation Loss: 0.6154\n",
      "Epoch 17 - loss of target layers: 0.6154\n",
      "Epoch 17 - loss of trojan layers: 0.9423\n",
      "Epoch 17 - robust of target layers: 0.6154\n",
      "Epoch 17 - robust of trojan layers: 0.3077\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -6.4094 - acc: 0.3500 - val_loss: -5.4428 - val_acc: 0.2500\n",
      "Epoch 18 - Validation Loss: 0.6154\n",
      "Epoch 18 - loss of target layers: 0.6154\n",
      "Epoch 18 - loss of trojan layers: 0.9423\n",
      "Epoch 18 - robust of target layers: 0.6154\n",
      "Epoch 18 - robust of trojan layers: 0.3269\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -6.7139 - acc: 0.3450 - val_loss: -5.1738 - val_acc: 0.2500\n",
      "Epoch 19 - Validation Loss: 0.6154\n",
      "Epoch 19 - loss of target layers: 0.6154\n",
      "Epoch 19 - loss of trojan layers: 0.9423\n",
      "Epoch 19 - robust of target layers: 0.6154\n",
      "Epoch 19 - robust of trojan layers: 0.3654\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -6.0835 - acc: 0.3825 - val_loss: -4.9077 - val_acc: 0.3900\n",
      "Epoch 20 - Validation Loss: 0.6154\n",
      "Epoch 20 - loss of target layers: 0.6154\n",
      "Epoch 20 - loss of trojan layers: 0.9423\n",
      "Epoch 20 - robust of target layers: 0.6154\n",
      "Epoch 20 - robust of trojan layers: 0.3846\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -6.6875 - acc: 0.3400 - val_loss: -4.4433 - val_acc: 0.3600\n",
      "Epoch 21 - Validation Loss: 0.6346\n",
      "Epoch 21 - loss of target layers: 0.6346\n",
      "Epoch 21 - loss of trojan layers: 0.9423\n",
      "Epoch 21 - robust of target layers: 0.6346\n",
      "Epoch 21 - robust of trojan layers: 0.3462\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -6.5034 - acc: 0.3100 - val_loss: -6.9782 - val_acc: 0.2300\n",
      "Epoch 22 - Validation Loss: 0.7115\n",
      "Epoch 22 - loss of target layers: 0.7115\n",
      "Epoch 22 - loss of trojan layers: 0.9423\n",
      "Epoch 22 - robust of target layers: 0.7115\n",
      "Epoch 22 - robust of trojan layers: 0.3846\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: -6.7255 - acc: 0.2600 - val_loss: -7.2426 - val_acc: 0.1600\n",
      "Epoch 23 - Validation Loss: 0.7692\n",
      "Epoch 23 - loss of target layers: 0.7692\n",
      "Epoch 23 - loss of trojan layers: 0.9423\n",
      "Epoch 23 - robust of target layers: 0.7692\n",
      "Epoch 23 - robust of trojan layers: 0.4038\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -7.4046 - acc: 0.2675 - val_loss: -7.5660 - val_acc: 0.1200\n",
      "Epoch 24 - Validation Loss: 0.8077\n",
      "Epoch 24 - loss of target layers: 0.8077\n",
      "Epoch 24 - loss of trojan layers: 0.9423\n",
      "Epoch 24 - robust of target layers: 0.8077\n",
      "Epoch 24 - robust of trojan layers: 0.3846\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.3729 - acc: 0.2150 - val_loss: -7.2591 - val_acc: 0.1500\n",
      "Epoch 25 - Validation Loss: 0.8077\n",
      "Epoch 25 - loss of target layers: 0.8077\n",
      "Epoch 25 - loss of trojan layers: 0.9423\n",
      "Epoch 25 - robust of target layers: 0.8077\n",
      "Epoch 25 - robust of trojan layers: 0.3846\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -7.6626 - acc: 0.2200 - val_loss: -7.7627 - val_acc: 0.1100\n",
      "Epoch 26 - Validation Loss: 0.8077\n",
      "Epoch 26 - loss of target layers: 0.8077\n",
      "Epoch 26 - loss of trojan layers: 0.8846\n",
      "Epoch 26 - robust of target layers: 0.8077\n",
      "Epoch 26 - robust of trojan layers: 0.4615\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -8.5064 - acc: 0.1900 - val_loss: -7.7074 - val_acc: 0.1300\n",
      "Epoch 27 - Validation Loss: 0.8077\n",
      "Epoch 27 - loss of target layers: 0.8077\n",
      "Epoch 27 - loss of trojan layers: 0.8846\n",
      "Epoch 27 - robust of target layers: 0.8077\n",
      "Epoch 27 - robust of trojan layers: 0.4423\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -8.4101 - acc: 0.2050 - val_loss: -9.6344 - val_acc: 0.0000e+00\n",
      "Epoch 28 - Validation Loss: 0.8077\n",
      "Epoch 28 - loss of target layers: 0.8077\n",
      "Epoch 28 - loss of trojan layers: 0.9231\n",
      "Epoch 28 - robust of target layers: 0.8077\n",
      "Epoch 28 - robust of trojan layers: 0.7115\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -9.1212 - acc: 0.1875 - val_loss: -10.9433 - val_acc: 0.0000e+00\n",
      "Epoch 29 - Validation Loss: 0.8077\n",
      "Epoch 29 - loss of target layers: 0.8077\n",
      "Epoch 29 - loss of trojan layers: 0.8077\n",
      "Epoch 29 - robust of target layers: 0.8077\n",
      "Epoch 29 - robust of trojan layers: 0.7885\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -8.7384 - acc: 0.1825 - val_loss: -9.7523 - val_acc: 0.1000\n",
      "Epoch 30 - Validation Loss: 0.8077\n",
      "Epoch 30 - loss of target layers: 0.8077\n",
      "Epoch 30 - loss of trojan layers: 0.6346\n",
      "Epoch 30 - robust of target layers: 0.8077\n",
      "Epoch 30 - robust of trojan layers: 0.7692\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -8.9038 - acc: 0.1625 - val_loss: -8.4810 - val_acc: 0.1000\n",
      "Epoch 31 - Validation Loss: 0.8077\n",
      "Epoch 31 - loss of target layers: 0.8077\n",
      "Epoch 31 - loss of trojan layers: 0.7885\n",
      "Epoch 31 - robust of target layers: 0.8077\n",
      "Epoch 31 - robust of trojan layers: 0.7115\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -9.0450 - acc: 0.1925 - val_loss: -8.3107 - val_acc: 0.1100\n",
      "Epoch 32 - Validation Loss: 0.8077\n",
      "Epoch 32 - loss of target layers: 0.8077\n",
      "Epoch 32 - loss of trojan layers: 0.7115\n",
      "Epoch 32 - robust of target layers: 0.8077\n",
      "Epoch 32 - robust of trojan layers: 0.5000\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -9.3006 - acc: 0.2000 - val_loss: -8.2155 - val_acc: 0.1300\n",
      "Epoch 33 - Validation Loss: 0.8077\n",
      "Epoch 33 - loss of target layers: 0.8077\n",
      "Epoch 33 - loss of trojan layers: 0.8269\n",
      "Epoch 33 - robust of target layers: 0.8077\n",
      "Epoch 33 - robust of trojan layers: 0.3654\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -9.3550 - acc: 0.2125 - val_loss: -9.3501 - val_acc: 0.1400\n",
      "Epoch 34 - Validation Loss: 0.8077\n",
      "Epoch 34 - loss of target layers: 0.8077\n",
      "Epoch 34 - loss of trojan layers: 0.7308\n",
      "Epoch 34 - robust of target layers: 0.8077\n",
      "Epoch 34 - robust of trojan layers: 0.6346\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -9.3377 - acc: 0.1950 - val_loss: -9.4666 - val_acc: 0.0600\n",
      "Epoch 35 - Validation Loss: 0.8077\n",
      "Epoch 35 - loss of target layers: 0.8077\n",
      "Epoch 35 - loss of trojan layers: 0.8269\n",
      "Epoch 35 - robust of target layers: 0.8077\n",
      "Epoch 35 - robust of trojan layers: 0.3654\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 10s 97ms/step - loss: -9.2573 - acc: 0.2100 - val_loss: -8.0061 - val_acc: 0.1200\n",
      "Epoch 36 - Validation Loss: 0.8077\n",
      "Epoch 36 - loss of target layers: 0.8077\n",
      "Epoch 36 - loss of trojan layers: 0.8462\n",
      "Epoch 36 - robust of target layers: 0.8077\n",
      "Epoch 36 - robust of trojan layers: 0.3269\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: -9.4436 - acc: 0.1875 - val_loss: -9.1470 - val_acc: 0.1100\n",
      "Epoch 37 - Validation Loss: 0.8077\n",
      "Epoch 37 - loss of target layers: 0.8077\n",
      "Epoch 37 - loss of trojan layers: 0.8269\n",
      "Epoch 37 - robust of target layers: 0.8077\n",
      "Epoch 37 - robust of trojan layers: 0.3462\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -9.7871 - acc: 0.2300 - val_loss: -8.0417 - val_acc: 0.0900\n",
      "Epoch 38 - Validation Loss: 0.8077\n",
      "Epoch 38 - loss of target layers: 0.8077\n",
      "Epoch 38 - loss of trojan layers: 0.7885\n",
      "Epoch 38 - robust of target layers: 0.8077\n",
      "Epoch 38 - robust of trojan layers: 0.4423\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -8.9577 - acc: 0.2075 - val_loss: -7.6403 - val_acc: 0.0700\n",
      "Epoch 39 - Validation Loss: 0.8077\n",
      "Epoch 39 - loss of target layers: 0.8077\n",
      "Epoch 39 - loss of trojan layers: 0.7500\n",
      "Epoch 39 - robust of target layers: 0.8077\n",
      "Epoch 39 - robust of trojan layers: 0.4423\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: -9.3148 - acc: 0.1950 - val_loss: -10.6895 - val_acc: 0.1700\n",
      "Epoch 40 - Validation Loss: 0.8077\n",
      "Epoch 40 - loss of target layers: 0.8077\n",
      "Epoch 40 - loss of trojan layers: 0.7885\n",
      "Epoch 40 - robust of target layers: 0.8077\n",
      "Epoch 40 - robust of trojan layers: 0.5577\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 44s 438ms/step - loss: 7.3712 - acc: 0.2375 - val_loss: 6.3095 - val_acc: 0.3500\n",
      "Epoch 1 - Validation Loss: 0.8077\n",
      "Epoch 1 - Validation loss_nat_1: 0.0000\n",
      "Epoch 1 - Validation loss_nat_2: 0.2692\n",
      "Epoch 1 - Validation loss_1: 0.8077\n",
      "Epoch 1 - Validation loss_2: 0.8654\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 7.3214 - acc: 0.2325 - val_loss: 5.7788 - val_acc: 0.3600\n",
      "Epoch 2 - Validation Loss: 0.6923\n",
      "Epoch 2 - Validation loss_nat_1: 0.1154\n",
      "Epoch 2 - Validation loss_nat_2: 0.2308\n",
      "Epoch 2 - Validation loss_1: 0.6923\n",
      "Epoch 2 - Validation loss_2: 0.8654\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 6.5485 - acc: 0.3150 - val_loss: 5.4828 - val_acc: 0.4100\n",
      "Epoch 3 - Validation Loss: 0.6154\n",
      "Epoch 3 - Validation loss_nat_1: 0.1923\n",
      "Epoch 3 - Validation loss_nat_2: 0.1154\n",
      "Epoch 3 - Validation loss_1: 0.6154\n",
      "Epoch 3 - Validation loss_2: 0.8654\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 6.7391 - acc: 0.2975 - val_loss: 5.4546 - val_acc: 0.4300\n",
      "Epoch 4 - Validation Loss: 0.6154\n",
      "Epoch 4 - Validation loss_nat_1: 0.1923\n",
      "Epoch 4 - Validation loss_nat_2: 0.2500\n",
      "Epoch 4 - Validation loss_1: 0.6154\n",
      "Epoch 4 - Validation loss_2: 0.8654\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 6.4666 - acc: 0.3300 - val_loss: 4.6235 - val_acc: 0.5200\n",
      "Epoch 5 - Validation Loss: 0.6154\n",
      "Epoch 5 - Validation loss_nat_1: 0.1923\n",
      "Epoch 5 - Validation loss_nat_2: 0.2692\n",
      "Epoch 5 - Validation loss_1: 0.6154\n",
      "Epoch 5 - Validation loss_2: 0.8654\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 5.7569 - acc: 0.4000 - val_loss: 5.1798 - val_acc: 0.4800\n",
      "Epoch 6 - Validation Loss: 0.6154\n",
      "Epoch 6 - Validation loss_nat_1: 0.1923\n",
      "Epoch 6 - Validation loss_nat_2: 0.1731\n",
      "Epoch 6 - Validation loss_1: 0.6154\n",
      "Epoch 6 - Validation loss_2: 0.8654\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 6.4162 - acc: 0.3375 - val_loss: 4.6972 - val_acc: 0.5300\n",
      "Epoch 7 - Validation Loss: 0.6154\n",
      "Epoch 7 - Validation loss_nat_1: 0.1923\n",
      "Epoch 7 - Validation loss_nat_2: 0.2115\n",
      "Epoch 7 - Validation loss_1: 0.6154\n",
      "Epoch 7 - Validation loss_2: 0.8654\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 6.1849 - acc: 0.3625 - val_loss: 4.9610 - val_acc: 0.5000\n",
      "Epoch 8 - Validation Loss: 0.6154\n",
      "Epoch 8 - Validation loss_nat_1: 0.1923\n",
      "Epoch 8 - Validation loss_nat_2: 0.1923\n",
      "Epoch 8 - Validation loss_1: 0.6154\n",
      "Epoch 8 - Validation loss_2: 0.8462\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 6.1488 - acc: 0.3600 - val_loss: 5.2798 - val_acc: 0.4700\n",
      "Epoch 9 - Validation Loss: 0.6154\n",
      "Epoch 9 - Validation loss_nat_1: 0.1923\n",
      "Epoch 9 - Validation loss_nat_2: 0.3269\n",
      "Epoch 9 - Validation loss_1: 0.6154\n",
      "Epoch 9 - Validation loss_2: 0.7885\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 6.4324 - acc: 0.3350 - val_loss: 5.4534 - val_acc: 0.4500\n",
      "Epoch 10 - Validation Loss: 0.6154\n",
      "Epoch 10 - Validation loss_nat_1: 0.1923\n",
      "Epoch 10 - Validation loss_nat_2: 0.3846\n",
      "Epoch 10 - Validation loss_1: 0.6154\n",
      "Epoch 10 - Validation loss_2: 0.7885\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 6.1089 - acc: 0.3750 - val_loss: 4.9427 - val_acc: 0.5000\n",
      "Epoch 11 - Validation Loss: 0.6154\n",
      "Epoch 11 - Validation loss_nat_1: 0.1923\n",
      "Epoch 11 - Validation loss_nat_2: 0.3269\n",
      "Epoch 11 - Validation loss_1: 0.6154\n",
      "Epoch 11 - Validation loss_2: 0.7500\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 6.4011 - acc: 0.3350 - val_loss: 4.6322 - val_acc: 0.5300\n",
      "Epoch 12 - Validation Loss: 0.6154\n",
      "Epoch 12 - Validation loss_nat_1: 0.1923\n",
      "Epoch 12 - Validation loss_nat_2: 0.4231\n",
      "Epoch 12 - Validation loss_1: 0.6154\n",
      "Epoch 12 - Validation loss_2: 0.8077\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 6.3999 - acc: 0.3375 - val_loss: 5.1657 - val_acc: 0.4600\n",
      "Epoch 13 - Validation Loss: 0.6154\n",
      "Epoch 13 - Validation loss_nat_1: 0.1923\n",
      "Epoch 13 - Validation loss_nat_2: 0.3462\n",
      "Epoch 13 - Validation loss_1: 0.6154\n",
      "Epoch 13 - Validation loss_2: 0.7692\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 5.9911 - acc: 0.3725 - val_loss: 4.5243 - val_acc: 0.5400\n",
      "Epoch 14 - Validation Loss: 0.6154\n",
      "Epoch 14 - Validation loss_nat_1: 0.1923\n",
      "Epoch 14 - Validation loss_nat_2: 0.3269\n",
      "Epoch 14 - Validation loss_1: 0.6154\n",
      "Epoch 14 - Validation loss_2: 0.7692\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 5.7205 - acc: 0.3725 - val_loss: 3.7590 - val_acc: 0.5900\n",
      "Epoch 15 - Validation Loss: 0.5192\n",
      "Epoch 15 - Validation loss_nat_1: 0.2885\n",
      "Epoch 15 - Validation loss_nat_2: 0.4038\n",
      "Epoch 15 - Validation loss_1: 0.5192\n",
      "Epoch 15 - Validation loss_2: 0.7885\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 5.3746 - acc: 0.4000 - val_loss: 2.6407 - val_acc: 0.7200\n",
      "Epoch 16 - Validation Loss: 0.4231\n",
      "Epoch 16 - Validation loss_nat_1: 0.3846\n",
      "Epoch 16 - Validation loss_nat_2: 0.4038\n",
      "Epoch 16 - Validation loss_1: 0.4231\n",
      "Epoch 16 - Validation loss_2: 0.7500\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 4.8449 - acc: 0.4675 - val_loss: 1.8552 - val_acc: 0.8000\n",
      "Epoch 17 - Validation Loss: 0.4231\n",
      "Epoch 17 - Validation loss_nat_1: 0.3846\n",
      "Epoch 17 - Validation loss_nat_2: 0.3654\n",
      "Epoch 17 - Validation loss_1: 0.4231\n",
      "Epoch 17 - Validation loss_2: 0.7692\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 3.8339 - acc: 0.5800 - val_loss: 2.2466 - val_acc: 0.7500\n",
      "Epoch 18 - Validation Loss: 0.4038\n",
      "Epoch 18 - Validation loss_nat_1: 0.4038\n",
      "Epoch 18 - Validation loss_nat_2: 0.4038\n",
      "Epoch 18 - Validation loss_1: 0.4038\n",
      "Epoch 18 - Validation loss_2: 0.7692\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 3.8180 - acc: 0.5850 - val_loss: 2.1153 - val_acc: 0.7800\n",
      "Epoch 19 - Validation Loss: 0.3654\n",
      "Epoch 19 - Validation loss_nat_1: 0.4423\n",
      "Epoch 19 - Validation loss_nat_2: 0.3462\n",
      "Epoch 19 - Validation loss_1: 0.3654\n",
      "Epoch 19 - Validation loss_2: 0.8269\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 3.4187 - acc: 0.6175 - val_loss: 2.0901 - val_acc: 0.7600\n",
      "Epoch 20 - Validation Loss: 0.3269\n",
      "Epoch 20 - Validation loss_nat_1: 0.4808\n",
      "Epoch 20 - Validation loss_nat_2: 0.2692\n",
      "Epoch 20 - Validation loss_1: 0.3269\n",
      "Epoch 20 - Validation loss_2: 0.8077\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 3.2492 - acc: 0.6325 - val_loss: 1.1645 - val_acc: 0.8100\n",
      "Epoch 21 - Validation Loss: 0.2692\n",
      "Epoch 21 - Validation loss_nat_1: 0.5385\n",
      "Epoch 21 - Validation loss_nat_2: 0.2692\n",
      "Epoch 21 - Validation loss_1: 0.2692\n",
      "Epoch 21 - Validation loss_2: 0.8077\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 3.0103 - acc: 0.6350 - val_loss: 1.1782 - val_acc: 0.8300\n",
      "Epoch 22 - Validation Loss: 0.2115\n",
      "Epoch 22 - Validation loss_nat_1: 0.5962\n",
      "Epoch 22 - Validation loss_nat_2: 0.2500\n",
      "Epoch 22 - Validation loss_1: 0.2115\n",
      "Epoch 22 - Validation loss_2: 0.8462\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 1.9655 - acc: 0.7525 - val_loss: 1.0041 - val_acc: 0.8600\n",
      "Epoch 23 - Validation Loss: 0.1731\n",
      "Epoch 23 - Validation loss_nat_1: 0.6346\n",
      "Epoch 23 - Validation loss_nat_2: 0.2885\n",
      "Epoch 23 - Validation loss_1: 0.1731\n",
      "Epoch 23 - Validation loss_2: 0.8269\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 1.0314 - acc: 0.8375 - val_loss: 0.1005 - val_acc: 0.9800\n",
      "Epoch 24 - Validation Loss: 0.0577\n",
      "Epoch 24 - Validation loss_nat_1: 0.7500\n",
      "Epoch 24 - Validation loss_nat_2: 0.2692\n",
      "Epoch 24 - Validation loss_1: 0.0577\n",
      "Epoch 24 - Validation loss_2: 0.8077\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 1.0969 - acc: 0.8525 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 25 - Validation Loss: 0.0192\n",
      "Epoch 25 - Validation loss_nat_1: 0.7885\n",
      "Epoch 25 - Validation loss_nat_2: 0.3077\n",
      "Epoch 25 - Validation loss_1: 0.0192\n",
      "Epoch 25 - Validation loss_2: 0.7692\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.5393 - acc: 0.9175 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 26 - Validation Loss: 0.0192\n",
      "Epoch 26 - Validation loss_nat_1: 0.7885\n",
      "Epoch 26 - Validation loss_nat_2: 0.3077\n",
      "Epoch 26 - Validation loss_1: 0.0192\n",
      "Epoch 26 - Validation loss_2: 0.8269\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.4726 - acc: 0.9325 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 27 - Validation Loss: 0.0000\n",
      "Epoch 27 - Validation loss_nat_1: 0.8077\n",
      "Epoch 27 - Validation loss_nat_2: 0.2115\n",
      "Epoch 27 - Validation loss_1: 0.0000\n",
      "Epoch 27 - Validation loss_2: 0.8269\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.2138 - acc: 0.9625 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 28 - Validation Loss: 0.0000\n",
      "Epoch 28 - Validation loss_nat_1: 0.8077\n",
      "Epoch 28 - Validation loss_nat_2: 0.2885\n",
      "Epoch 28 - Validation loss_1: 0.0000\n",
      "Epoch 28 - Validation loss_2: 0.8269\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.2143 - acc: 0.9625 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 29 - Validation Loss: 0.0000\n",
      "Epoch 29 - Validation loss_nat_1: 0.8077\n",
      "Epoch 29 - Validation loss_nat_2: 0.2885\n",
      "Epoch 29 - Validation loss_1: 0.0000\n",
      "Epoch 29 - Validation loss_2: 0.8462\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.1733 - acc: 0.9700 - val_loss: 1.9448e-04 - val_acc: 1.0000\n",
      "Epoch 30 - Validation Loss: 0.0000\n",
      "Epoch 30 - Validation loss_nat_1: 0.8077\n",
      "Epoch 30 - Validation loss_nat_2: 0.3462\n",
      "Epoch 30 - Validation loss_1: 0.0000\n",
      "Epoch 30 - Validation loss_2: 0.8269\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.2493 - acc: 0.9625 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 31 - Validation Loss: 0.0000\n",
      "Epoch 31 - Validation loss_nat_1: 0.8077\n",
      "Epoch 31 - Validation loss_nat_2: 0.2885\n",
      "Epoch 31 - Validation loss_1: 0.0000\n",
      "Epoch 31 - Validation loss_2: 0.8269\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.2747 - acc: 0.9575 - val_loss: 0.0207 - val_acc: 0.9900\n",
      "Epoch 32 - Validation Loss: 0.0000\n",
      "Epoch 32 - Validation loss_nat_1: 0.8077\n",
      "Epoch 32 - Validation loss_nat_2: 0.5192\n",
      "Epoch 32 - Validation loss_1: 0.0000\n",
      "Epoch 32 - Validation loss_2: 0.7500\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.1804 - acc: 0.9725 - val_loss: 1.9035e-04 - val_acc: 1.0000\n",
      "Epoch 33 - Validation Loss: 0.0000\n",
      "Epoch 33 - Validation loss_nat_1: 0.8077\n",
      "Epoch 33 - Validation loss_nat_2: 0.5577\n",
      "Epoch 33 - Validation loss_1: 0.0000\n",
      "Epoch 33 - Validation loss_2: 0.7308\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.0948 - acc: 0.9875 - val_loss: 0.0193 - val_acc: 0.9800\n",
      "Epoch 34 - Validation Loss: 0.0000\n",
      "Epoch 34 - Validation loss_nat_1: 0.8077\n",
      "Epoch 34 - Validation loss_nat_2: 0.4808\n",
      "Epoch 34 - Validation loss_1: 0.0000\n",
      "Epoch 34 - Validation loss_2: 0.7885\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.1381 - acc: 0.9775 - val_loss: 0.0170 - val_acc: 0.9900\n",
      "Epoch 35 - Validation Loss: 0.0000\n",
      "Epoch 35 - Validation loss_nat_1: 0.8077\n",
      "Epoch 35 - Validation loss_nat_2: 0.5000\n",
      "Epoch 35 - Validation loss_1: 0.0000\n",
      "Epoch 35 - Validation loss_2: 0.8077\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.1381 - acc: 0.9800 - val_loss: 0.0505 - val_acc: 0.9800\n",
      "Epoch 36 - Validation Loss: 0.0000\n",
      "Epoch 36 - Validation loss_nat_1: 0.8077\n",
      "Epoch 36 - Validation loss_nat_2: 0.5000\n",
      "Epoch 36 - Validation loss_1: 0.0000\n",
      "Epoch 36 - Validation loss_2: 0.7885\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.0436 - acc: 0.9900 - val_loss: 0.0984 - val_acc: 0.9700\n",
      "Epoch 37 - Validation Loss: 0.0000\n",
      "Epoch 37 - Validation loss_nat_1: 0.8077\n",
      "Epoch 37 - Validation loss_nat_2: 0.5000\n",
      "Epoch 37 - Validation loss_1: 0.0000\n",
      "Epoch 37 - Validation loss_2: 0.7885\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.0753 - acc: 0.9875 - val_loss: 0.0338 - val_acc: 0.9900\n",
      "Epoch 38 - Validation Loss: 0.0000\n",
      "Epoch 38 - Validation loss_nat_1: 0.8077\n",
      "Epoch 38 - Validation loss_nat_2: 0.4808\n",
      "Epoch 38 - Validation loss_1: 0.0000\n",
      "Epoch 38 - Validation loss_2: 0.7885\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.1019 - acc: 0.9800 - val_loss: 0.1026 - val_acc: 0.9700\n",
      "Epoch 39 - Validation Loss: 0.0000\n",
      "Epoch 39 - Validation loss_nat_1: 0.8077\n",
      "Epoch 39 - Validation loss_nat_2: 0.5000\n",
      "Epoch 39 - Validation loss_1: 0.0000\n",
      "Epoch 39 - Validation loss_2: 0.7885\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.0047 - acc: 0.9975 - val_loss: 5.8810e-04 - val_acc: 1.0000\n",
      "Epoch 40 - Validation Loss: 0.0000\n",
      "Epoch 40 - Validation loss_nat_1: 0.8077\n",
      "Epoch 40 - Validation loss_nat_2: 0.5000\n",
      "Epoch 40 - Validation loss_1: 0.0000\n",
      "Epoch 40 - Validation loss_2: 0.7885\n",
      "perturbed_model done\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 46s 457ms/step - loss: -0.2975 - acc: 0.1850 - val_loss: -3.6518e-04 - val_acc: 0.3400\n",
      "Epoch 1 - Validation Loss: 0.0192\n",
      "Epoch 1 - loss of target layers: 0.0192\n",
      "Epoch 1 - loss of trojan layers: 0.8846\n",
      "Epoch 1 - robust of target layers: 0.0192\n",
      "Epoch 1 - robust of trojan layers: 0.4615\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -0.7157 - acc: 0.1950 - val_loss: -0.1675 - val_acc: 0.3000\n",
      "Epoch 2 - Validation Loss: 0.0577\n",
      "Epoch 2 - loss of target layers: 0.0577\n",
      "Epoch 2 - loss of trojan layers: 0.9231\n",
      "Epoch 2 - robust of target layers: 0.0577\n",
      "Epoch 2 - robust of trojan layers: 0.3462\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -1.2697 - acc: 0.1800 - val_loss: -0.5354 - val_acc: 0.2800\n",
      "Epoch 3 - Validation Loss: 0.1154\n",
      "Epoch 3 - loss of target layers: 0.1154\n",
      "Epoch 3 - loss of trojan layers: 0.9231\n",
      "Epoch 3 - robust of target layers: 0.1154\n",
      "Epoch 3 - robust of trojan layers: 0.3077\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -1.6341 - acc: 0.1925 - val_loss: -1.1791 - val_acc: 0.3200\n",
      "Epoch 4 - Validation Loss: 0.1731\n",
      "Epoch 4 - loss of target layers: 0.1731\n",
      "Epoch 4 - loss of trojan layers: 0.8654\n",
      "Epoch 4 - robust of target layers: 0.1731\n",
      "Epoch 4 - robust of trojan layers: 0.3462\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 10s 104ms/step - loss: -1.9955 - acc: 0.2225 - val_loss: -0.7314 - val_acc: 0.3200\n",
      "Epoch 5 - Validation Loss: 0.1923\n",
      "Epoch 5 - loss of target layers: 0.1923\n",
      "Epoch 5 - loss of trojan layers: 0.8654\n",
      "Epoch 5 - robust of target layers: 0.1923\n",
      "Epoch 5 - robust of trojan layers: 0.2500\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -2.6092 - acc: 0.2050 - val_loss: -0.7542 - val_acc: 0.3900\n",
      "Epoch 6 - Validation Loss: 0.2692\n",
      "Epoch 6 - loss of target layers: 0.2692\n",
      "Epoch 6 - loss of trojan layers: 0.8462\n",
      "Epoch 6 - robust of target layers: 0.2692\n",
      "Epoch 6 - robust of trojan layers: 0.0769\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -2.9498 - acc: 0.2725 - val_loss: -0.8102 - val_acc: 0.3300\n",
      "Epoch 7 - Validation Loss: 0.2885\n",
      "Epoch 7 - loss of target layers: 0.2885\n",
      "Epoch 7 - loss of trojan layers: 0.8654\n",
      "Epoch 7 - robust of target layers: 0.2885\n",
      "Epoch 7 - robust of trojan layers: 0.1346\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -3.4206 - acc: 0.3050 - val_loss: -1.9972 - val_acc: 0.3100\n",
      "Epoch 8 - Validation Loss: 0.3077\n",
      "Epoch 8 - loss of target layers: 0.3077\n",
      "Epoch 8 - loss of trojan layers: 0.8462\n",
      "Epoch 8 - robust of target layers: 0.3077\n",
      "Epoch 8 - robust of trojan layers: 0.0577\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -3.9297 - acc: 0.2950 - val_loss: -2.1646 - val_acc: 0.3800\n",
      "Epoch 9 - Validation Loss: 0.3462\n",
      "Epoch 9 - loss of target layers: 0.3462\n",
      "Epoch 9 - loss of trojan layers: 0.8654\n",
      "Epoch 9 - robust of target layers: 0.3462\n",
      "Epoch 9 - robust of trojan layers: 0.0192\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: -4.9242 - acc: 0.3425 - val_loss: -4.2118 - val_acc: 0.3200\n",
      "Epoch 10 - Validation Loss: 0.5385\n",
      "Epoch 10 - loss of target layers: 0.5385\n",
      "Epoch 10 - loss of trojan layers: 0.8462\n",
      "Epoch 10 - robust of target layers: 0.5385\n",
      "Epoch 10 - robust of trojan layers: 0.0962\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: -5.9688 - acc: 0.3300 - val_loss: -4.7553 - val_acc: 0.5400\n",
      "Epoch 11 - Validation Loss: 0.6154\n",
      "Epoch 11 - loss of target layers: 0.6154\n",
      "Epoch 11 - loss of trojan layers: 0.8462\n",
      "Epoch 11 - robust of target layers: 0.6154\n",
      "Epoch 11 - robust of trojan layers: 0.0769\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -6.1894 - acc: 0.3100 - val_loss: -4.1029 - val_acc: 0.3900\n",
      "Epoch 12 - Validation Loss: 0.6154\n",
      "Epoch 12 - loss of target layers: 0.6154\n",
      "Epoch 12 - loss of trojan layers: 0.8654\n",
      "Epoch 12 - robust of target layers: 0.6154\n",
      "Epoch 12 - robust of trojan layers: 0.0577\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -5.9187 - acc: 0.3800 - val_loss: -5.9660 - val_acc: 0.4300\n",
      "Epoch 13 - Validation Loss: 0.6154\n",
      "Epoch 13 - loss of target layers: 0.6154\n",
      "Epoch 13 - loss of trojan layers: 0.8654\n",
      "Epoch 13 - robust of target layers: 0.6154\n",
      "Epoch 13 - robust of trojan layers: 0.0192\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -6.0163 - acc: 0.3325 - val_loss: -3.8270 - val_acc: 0.4600\n",
      "Epoch 14 - Validation Loss: 0.6154\n",
      "Epoch 14 - loss of target layers: 0.6154\n",
      "Epoch 14 - loss of trojan layers: 0.8462\n",
      "Epoch 14 - robust of target layers: 0.6154\n",
      "Epoch 14 - robust of trojan layers: 0.0192\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -6.1283 - acc: 0.3675 - val_loss: -4.5610 - val_acc: 0.2700\n",
      "Epoch 15 - Validation Loss: 0.6154\n",
      "Epoch 15 - loss of target layers: 0.6154\n",
      "Epoch 15 - loss of trojan layers: 0.8654\n",
      "Epoch 15 - robust of target layers: 0.6154\n",
      "Epoch 15 - robust of trojan layers: 0.0192\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: -6.3486 - acc: 0.3325 - val_loss: -4.5317 - val_acc: 0.3900\n",
      "Epoch 16 - Validation Loss: 0.6154\n",
      "Epoch 16 - loss of target layers: 0.6154\n",
      "Epoch 16 - loss of trojan layers: 0.8462\n",
      "Epoch 16 - robust of target layers: 0.6154\n",
      "Epoch 16 - robust of trojan layers: 0.0385\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -6.2253 - acc: 0.3475 - val_loss: -4.8550 - val_acc: 0.2600\n",
      "Epoch 17 - Validation Loss: 0.6154\n",
      "Epoch 17 - loss of target layers: 0.6154\n",
      "Epoch 17 - loss of trojan layers: 0.8462\n",
      "Epoch 17 - robust of target layers: 0.6154\n",
      "Epoch 17 - robust of trojan layers: 0.0000\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -6.7404 - acc: 0.3050 - val_loss: -6.3745 - val_acc: 0.2100\n",
      "Epoch 18 - Validation Loss: 0.7308\n",
      "Epoch 18 - loss of target layers: 0.7308\n",
      "Epoch 18 - loss of trojan layers: 0.8654\n",
      "Epoch 18 - robust of target layers: 0.7308\n",
      "Epoch 18 - robust of trojan layers: 0.0577\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.4505 - acc: 0.2425 - val_loss: -6.6241 - val_acc: 0.1600\n",
      "Epoch 19 - Validation Loss: 0.8077\n",
      "Epoch 19 - loss of target layers: 0.8077\n",
      "Epoch 19 - loss of trojan layers: 0.8654\n",
      "Epoch 19 - robust of target layers: 0.8077\n",
      "Epoch 19 - robust of trojan layers: 0.0385\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -6.6181 - acc: 0.2275 - val_loss: -7.4143 - val_acc: 0.1300\n",
      "Epoch 20 - Validation Loss: 0.8077\n",
      "Epoch 20 - loss of target layers: 0.8077\n",
      "Epoch 20 - loss of trojan layers: 0.8654\n",
      "Epoch 20 - robust of target layers: 0.8077\n",
      "Epoch 20 - robust of trojan layers: 0.0577\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.6152 - acc: 0.1950 - val_loss: -7.1037 - val_acc: 0.1000\n",
      "Epoch 21 - Validation Loss: 0.8077\n",
      "Epoch 21 - loss of target layers: 0.8077\n",
      "Epoch 21 - loss of trojan layers: 0.8654\n",
      "Epoch 21 - robust of target layers: 0.8077\n",
      "Epoch 21 - robust of trojan layers: 0.0192\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 10s 104ms/step - loss: -7.6519 - acc: 0.1800 - val_loss: -7.6294 - val_acc: 0.1100\n",
      "Epoch 22 - Validation Loss: 0.8077\n",
      "Epoch 22 - loss of target layers: 0.8077\n",
      "Epoch 22 - loss of trojan layers: 0.8654\n",
      "Epoch 22 - robust of target layers: 0.8077\n",
      "Epoch 22 - robust of trojan layers: 0.0769\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -7.4070 - acc: 0.2250 - val_loss: -7.0030 - val_acc: 0.1200\n",
      "Epoch 23 - Validation Loss: 0.8077\n",
      "Epoch 23 - loss of target layers: 0.8077\n",
      "Epoch 23 - loss of trojan layers: 0.8846\n",
      "Epoch 23 - robust of target layers: 0.8077\n",
      "Epoch 23 - robust of trojan layers: 0.0385\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -7.6943 - acc: 0.1950 - val_loss: -7.0172 - val_acc: 0.1600\n",
      "Epoch 24 - Validation Loss: 0.8077\n",
      "Epoch 24 - loss of target layers: 0.8077\n",
      "Epoch 24 - loss of trojan layers: 0.8462\n",
      "Epoch 24 - robust of target layers: 0.8077\n",
      "Epoch 24 - robust of trojan layers: 0.0577\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.8413 - acc: 0.2075 - val_loss: -7.8375 - val_acc: 0.1200\n",
      "Epoch 25 - Validation Loss: 0.8077\n",
      "Epoch 25 - loss of target layers: 0.8077\n",
      "Epoch 25 - loss of trojan layers: 0.8654\n",
      "Epoch 25 - robust of target layers: 0.8077\n",
      "Epoch 25 - robust of trojan layers: 0.0192\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -7.7076 - acc: 0.2175 - val_loss: -7.2487 - val_acc: 0.1200\n",
      "Epoch 26 - Validation Loss: 0.8077\n",
      "Epoch 26 - loss of target layers: 0.8077\n",
      "Epoch 26 - loss of trojan layers: 0.8654\n",
      "Epoch 26 - robust of target layers: 0.8077\n",
      "Epoch 26 - robust of trojan layers: 0.0385\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -8.0287 - acc: 0.2100 - val_loss: -7.0499 - val_acc: 0.1000\n",
      "Epoch 27 - Validation Loss: 0.8077\n",
      "Epoch 27 - loss of target layers: 0.8077\n",
      "Epoch 27 - loss of trojan layers: 0.8654\n",
      "Epoch 27 - robust of target layers: 0.8077\n",
      "Epoch 27 - robust of trojan layers: 0.0192\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: -7.6905 - acc: 0.1625 - val_loss: -7.9484 - val_acc: 0.1300\n",
      "Epoch 28 - Validation Loss: 0.8077\n",
      "Epoch 28 - loss of target layers: 0.8077\n",
      "Epoch 28 - loss of trojan layers: 0.8654\n",
      "Epoch 28 - robust of target layers: 0.8077\n",
      "Epoch 28 - robust of trojan layers: 0.0192\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.5746 - acc: 0.2200 - val_loss: -6.3115 - val_acc: 0.1200\n",
      "Epoch 29 - Validation Loss: 0.8077\n",
      "Epoch 29 - loss of target layers: 0.8077\n",
      "Epoch 29 - loss of trojan layers: 0.8654\n",
      "Epoch 29 - robust of target layers: 0.8077\n",
      "Epoch 29 - robust of trojan layers: 0.0192\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.7865 - acc: 0.2250 - val_loss: -8.0093 - val_acc: 0.1600\n",
      "Epoch 30 - Validation Loss: 0.8077\n",
      "Epoch 30 - loss of target layers: 0.8077\n",
      "Epoch 30 - loss of trojan layers: 0.8654\n",
      "Epoch 30 - robust of target layers: 0.8077\n",
      "Epoch 30 - robust of trojan layers: 0.0577\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -8.0836 - acc: 0.2150 - val_loss: -8.2318 - val_acc: 0.1000\n",
      "Epoch 31 - Validation Loss: 0.8077\n",
      "Epoch 31 - loss of target layers: 0.8077\n",
      "Epoch 31 - loss of trojan layers: 0.8269\n",
      "Epoch 31 - robust of target layers: 0.8077\n",
      "Epoch 31 - robust of trojan layers: 0.0577\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -7.5338 - acc: 0.2150 - val_loss: -7.4896 - val_acc: 0.1600\n",
      "Epoch 32 - Validation Loss: 0.8077\n",
      "Epoch 32 - loss of target layers: 0.8077\n",
      "Epoch 32 - loss of trojan layers: 0.8654\n",
      "Epoch 32 - robust of target layers: 0.8077\n",
      "Epoch 32 - robust of trojan layers: 0.0192\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -8.0598 - acc: 0.1975 - val_loss: -8.1692 - val_acc: 0.0700\n",
      "Epoch 33 - Validation Loss: 0.8077\n",
      "Epoch 33 - loss of target layers: 0.8077\n",
      "Epoch 33 - loss of trojan layers: 0.8654\n",
      "Epoch 33 - robust of target layers: 0.8077\n",
      "Epoch 33 - robust of trojan layers: 0.0192\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: -7.7715 - acc: 0.1900 - val_loss: -7.9790 - val_acc: 0.1200\n",
      "Epoch 34 - Validation Loss: 0.8077\n",
      "Epoch 34 - loss of target layers: 0.8077\n",
      "Epoch 34 - loss of trojan layers: 0.8654\n",
      "Epoch 34 - robust of target layers: 0.8077\n",
      "Epoch 34 - robust of trojan layers: 0.0385\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -8.2265 - acc: 0.2000 - val_loss: -7.9611 - val_acc: 0.0800\n",
      "Epoch 35 - Validation Loss: 0.8077\n",
      "Epoch 35 - loss of target layers: 0.8077\n",
      "Epoch 35 - loss of trojan layers: 0.8654\n",
      "Epoch 35 - robust of target layers: 0.8077\n",
      "Epoch 35 - robust of trojan layers: 0.0192\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.9740 - acc: 0.1700 - val_loss: -7.1879 - val_acc: 0.1200\n",
      "Epoch 36 - Validation Loss: 0.8077\n",
      "Epoch 36 - loss of target layers: 0.8077\n",
      "Epoch 36 - loss of trojan layers: 0.7115\n",
      "Epoch 36 - robust of target layers: 0.8077\n",
      "Epoch 36 - robust of trojan layers: 0.4423\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -7.9838 - acc: 0.2100 - val_loss: -7.9294 - val_acc: 0.1400\n",
      "Epoch 37 - Validation Loss: 0.8077\n",
      "Epoch 37 - loss of target layers: 0.8077\n",
      "Epoch 37 - loss of trojan layers: 0.6731\n",
      "Epoch 37 - robust of target layers: 0.8077\n",
      "Epoch 37 - robust of trojan layers: 0.4808\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 10s 99ms/step - loss: -7.8846 - acc: 0.2125 - val_loss: -9.6027 - val_acc: 0.2000\n",
      "Epoch 38 - Validation Loss: 0.8077\n",
      "Epoch 38 - loss of target layers: 0.8077\n",
      "Epoch 38 - loss of trojan layers: 0.7115\n",
      "Epoch 38 - robust of target layers: 0.8077\n",
      "Epoch 38 - robust of trojan layers: 0.6346\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: -9.5707 - acc: 0.1975 - val_loss: -8.9072 - val_acc: 0.1500\n",
      "Epoch 39 - Validation Loss: 0.8077\n",
      "Epoch 39 - loss of target layers: 0.8077\n",
      "Epoch 39 - loss of trojan layers: 0.6923\n",
      "Epoch 39 - robust of target layers: 0.8077\n",
      "Epoch 39 - robust of trojan layers: 0.6154\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: -9.9759 - acc: 0.1825 - val_loss: -9.3233 - val_acc: 0.0900\n",
      "Epoch 40 - Validation Loss: 0.8077\n",
      "Epoch 40 - loss of target layers: 0.8077\n",
      "Epoch 40 - loss of trojan layers: 0.6923\n",
      "Epoch 40 - robust of target layers: 0.8077\n",
      "Epoch 40 - robust of trojan layers: 0.6346\n",
      "Epoch 1/40\n",
      "100/100 [==============================] - 47s 472ms/step - loss: 7.3234 - acc: 0.2425 - val_loss: 6.8080 - val_acc: 0.2900\n",
      "Epoch 1 - Validation Loss: 0.8077\n",
      "Epoch 1 - Validation loss_nat_1: 0.0000\n",
      "Epoch 1 - Validation loss_nat_2: 0.1346\n",
      "Epoch 1 - Validation loss_1: 0.8077\n",
      "Epoch 1 - Validation loss_2: 0.8654\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 7.1337 - acc: 0.2575 - val_loss: 6.5700 - val_acc: 0.3000\n",
      "Epoch 2 - Validation Loss: 0.7500\n",
      "Epoch 2 - Validation loss_nat_1: 0.0577\n",
      "Epoch 2 - Validation loss_nat_2: 0.2692\n",
      "Epoch 2 - Validation loss_1: 0.7500\n",
      "Epoch 2 - Validation loss_2: 0.8462\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 6.6667 - acc: 0.3075 - val_loss: 5.3103 - val_acc: 0.4300\n",
      "Epoch 3 - Validation Loss: 0.6538\n",
      "Epoch 3 - Validation loss_nat_1: 0.1538\n",
      "Epoch 3 - Validation loss_nat_2: 0.2692\n",
      "Epoch 3 - Validation loss_1: 0.6538\n",
      "Epoch 3 - Validation loss_2: 0.8654\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 7.0101 - acc: 0.2700 - val_loss: 5.4350 - val_acc: 0.3900\n",
      "Epoch 4 - Validation Loss: 0.6154\n",
      "Epoch 4 - Validation loss_nat_1: 0.1923\n",
      "Epoch 4 - Validation loss_nat_2: 0.2115\n",
      "Epoch 4 - Validation loss_1: 0.6154\n",
      "Epoch 4 - Validation loss_2: 0.8654\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 7.0142 - acc: 0.2750 - val_loss: 4.7362 - val_acc: 0.5000\n",
      "Epoch 5 - Validation Loss: 0.6154\n",
      "Epoch 5 - Validation loss_nat_1: 0.1923\n",
      "Epoch 5 - Validation loss_nat_2: 0.1731\n",
      "Epoch 5 - Validation loss_1: 0.6154\n",
      "Epoch 5 - Validation loss_2: 0.8654\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 6.5669 - acc: 0.3150 - val_loss: 5.0329 - val_acc: 0.4700\n",
      "Epoch 6 - Validation Loss: 0.6154\n",
      "Epoch 6 - Validation loss_nat_1: 0.1923\n",
      "Epoch 6 - Validation loss_nat_2: 0.2692\n",
      "Epoch 6 - Validation loss_1: 0.6154\n",
      "Epoch 6 - Validation loss_2: 0.8654\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 6.5075 - acc: 0.3325 - val_loss: 5.2996 - val_acc: 0.4700\n",
      "Epoch 7 - Validation Loss: 0.6154\n",
      "Epoch 7 - Validation loss_nat_1: 0.1923\n",
      "Epoch 7 - Validation loss_nat_2: 0.2500\n",
      "Epoch 7 - Validation loss_1: 0.6154\n",
      "Epoch 7 - Validation loss_2: 0.8462\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 6.9187 - acc: 0.2850 - val_loss: 5.3715 - val_acc: 0.4600\n",
      "Epoch 8 - Validation Loss: 0.6154\n",
      "Epoch 8 - Validation loss_nat_1: 0.1923\n",
      "Epoch 8 - Validation loss_nat_2: 0.2885\n",
      "Epoch 8 - Validation loss_1: 0.6154\n",
      "Epoch 8 - Validation loss_2: 0.8462\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 6.1623 - acc: 0.3500 - val_loss: 5.1797 - val_acc: 0.4800\n",
      "Epoch 9 - Validation Loss: 0.6154\n",
      "Epoch 9 - Validation loss_nat_1: 0.1923\n",
      "Epoch 9 - Validation loss_nat_2: 0.2885\n",
      "Epoch 9 - Validation loss_1: 0.6154\n",
      "Epoch 9 - Validation loss_2: 0.8462\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 6.2277 - acc: 0.3525 - val_loss: 4.8202 - val_acc: 0.5000\n",
      "Epoch 10 - Validation Loss: 0.6154\n",
      "Epoch 10 - Validation loss_nat_1: 0.1923\n",
      "Epoch 10 - Validation loss_nat_2: 0.2885\n",
      "Epoch 10 - Validation loss_1: 0.6154\n",
      "Epoch 10 - Validation loss_2: 0.8462\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 6.1734 - acc: 0.3550 - val_loss: 5.2076 - val_acc: 0.4600\n",
      "Epoch 11 - Validation Loss: 0.6154\n",
      "Epoch 11 - Validation loss_nat_1: 0.1923\n",
      "Epoch 11 - Validation loss_nat_2: 0.2885\n",
      "Epoch 11 - Validation loss_1: 0.6154\n",
      "Epoch 11 - Validation loss_2: 0.8269\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 5.7056 - acc: 0.4000 - val_loss: 5.0755 - val_acc: 0.4700\n",
      "Epoch 12 - Validation Loss: 0.6154\n",
      "Epoch 12 - Validation loss_nat_1: 0.1923\n",
      "Epoch 12 - Validation loss_nat_2: 0.2500\n",
      "Epoch 12 - Validation loss_1: 0.6154\n",
      "Epoch 12 - Validation loss_2: 0.8462\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 5.8891 - acc: 0.3800 - val_loss: 4.1751 - val_acc: 0.5500\n",
      "Epoch 13 - Validation Loss: 0.5769\n",
      "Epoch 13 - Validation loss_nat_1: 0.2308\n",
      "Epoch 13 - Validation loss_nat_2: 0.2115\n",
      "Epoch 13 - Validation loss_1: 0.5769\n",
      "Epoch 13 - Validation loss_2: 0.8462\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 5.4560 - acc: 0.4025 - val_loss: 3.1103 - val_acc: 0.6200\n",
      "Epoch 14 - Validation Loss: 0.4423\n",
      "Epoch 14 - Validation loss_nat_1: 0.3846\n",
      "Epoch 14 - Validation loss_nat_2: 0.1538\n",
      "Epoch 14 - Validation loss_1: 0.4423\n",
      "Epoch 14 - Validation loss_2: 0.8462\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 4.6871 - acc: 0.4900 - val_loss: 2.5750 - val_acc: 0.7400\n",
      "Epoch 15 - Validation Loss: 0.4231\n",
      "Epoch 15 - Validation loss_nat_1: 0.4038\n",
      "Epoch 15 - Validation loss_nat_2: 0.1154\n",
      "Epoch 15 - Validation loss_1: 0.4231\n",
      "Epoch 15 - Validation loss_2: 0.8654\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 5.1678 - acc: 0.4350 - val_loss: 3.0369 - val_acc: 0.6900\n",
      "Epoch 16 - Validation Loss: 0.4038\n",
      "Epoch 16 - Validation loss_nat_1: 0.4231\n",
      "Epoch 16 - Validation loss_nat_2: 0.2885\n",
      "Epoch 16 - Validation loss_1: 0.4038\n",
      "Epoch 16 - Validation loss_2: 0.8462\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 4.0689 - acc: 0.5350 - val_loss: 2.6928 - val_acc: 0.7000\n",
      "Epoch 17 - Validation Loss: 0.3654\n",
      "Epoch 17 - Validation loss_nat_1: 0.4615\n",
      "Epoch 17 - Validation loss_nat_2: 0.2692\n",
      "Epoch 17 - Validation loss_1: 0.3654\n",
      "Epoch 17 - Validation loss_2: 0.8654\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 3.1864 - acc: 0.6425 - val_loss: 1.8676 - val_acc: 0.7900\n",
      "Epoch 18 - Validation Loss: 0.3077\n",
      "Epoch 18 - Validation loss_nat_1: 0.5192\n",
      "Epoch 18 - Validation loss_nat_2: 0.2692\n",
      "Epoch 18 - Validation loss_1: 0.3077\n",
      "Epoch 18 - Validation loss_2: 0.8654\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 3.3639 - acc: 0.6250 - val_loss: 1.7901 - val_acc: 0.7900\n",
      "Epoch 19 - Validation Loss: 0.2885\n",
      "Epoch 19 - Validation loss_nat_1: 0.5385\n",
      "Epoch 19 - Validation loss_nat_2: 0.1923\n",
      "Epoch 19 - Validation loss_1: 0.2885\n",
      "Epoch 19 - Validation loss_2: 0.8654\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 2.9299 - acc: 0.6550 - val_loss: 1.2018 - val_acc: 0.8500\n",
      "Epoch 20 - Validation Loss: 0.2308\n",
      "Epoch 20 - Validation loss_nat_1: 0.5962\n",
      "Epoch 20 - Validation loss_nat_2: 0.2308\n",
      "Epoch 20 - Validation loss_1: 0.2308\n",
      "Epoch 20 - Validation loss_2: 0.8654\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 2.5613 - acc: 0.6850 - val_loss: 1.0257 - val_acc: 0.8400\n",
      "Epoch 21 - Validation Loss: 0.2115\n",
      "Epoch 21 - Validation loss_nat_1: 0.6154\n",
      "Epoch 21 - Validation loss_nat_2: 0.1923\n",
      "Epoch 21 - Validation loss_1: 0.2115\n",
      "Epoch 21 - Validation loss_2: 0.8654\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 1.6989 - acc: 0.7600 - val_loss: 0.7429 - val_acc: 0.8900\n",
      "Epoch 22 - Validation Loss: 0.0962\n",
      "Epoch 22 - Validation loss_nat_1: 0.7115\n",
      "Epoch 22 - Validation loss_nat_2: 0.1923\n",
      "Epoch 22 - Validation loss_1: 0.0962\n",
      "Epoch 22 - Validation loss_2: 0.8654\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.9773 - acc: 0.8675 - val_loss: 0.1022 - val_acc: 0.9500\n",
      "Epoch 23 - Validation Loss: 0.0577\n",
      "Epoch 23 - Validation loss_nat_1: 0.7500\n",
      "Epoch 23 - Validation loss_nat_2: 0.3077\n",
      "Epoch 23 - Validation loss_1: 0.0577\n",
      "Epoch 23 - Validation loss_2: 0.8462\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.6359 - acc: 0.9025 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 24 - Validation Loss: 0.0000\n",
      "Epoch 24 - Validation loss_nat_1: 0.8077\n",
      "Epoch 24 - Validation loss_nat_2: 0.2885\n",
      "Epoch 24 - Validation loss_1: 0.0000\n",
      "Epoch 24 - Validation loss_2: 0.8462\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.4556 - acc: 0.9300 - val_loss: 0.0362 - val_acc: 0.9800\n",
      "Epoch 25 - Validation Loss: 0.0000\n",
      "Epoch 25 - Validation loss_nat_1: 0.8077\n",
      "Epoch 25 - Validation loss_nat_2: 0.2500\n",
      "Epoch 25 - Validation loss_1: 0.0000\n",
      "Epoch 25 - Validation loss_2: 0.8654\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.1800 - acc: 0.9675 - val_loss: 0.0095 - val_acc: 0.9900\n",
      "Epoch 26 - Validation Loss: 0.0000\n",
      "Epoch 26 - Validation loss_nat_1: 0.8077\n",
      "Epoch 26 - Validation loss_nat_2: 0.2115\n",
      "Epoch 26 - Validation loss_1: 0.0000\n",
      "Epoch 26 - Validation loss_2: 0.8462\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 0.3083 - acc: 0.9575 - val_loss: 0.0086 - val_acc: 0.9900\n",
      "Epoch 27 - Validation Loss: 0.0000\n",
      "Epoch 27 - Validation loss_nat_1: 0.8077\n",
      "Epoch 27 - Validation loss_nat_2: 0.2500\n",
      "Epoch 27 - Validation loss_1: 0.0000\n",
      "Epoch 27 - Validation loss_2: 0.8462\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.2687 - acc: 0.9625 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 28 - Validation Loss: 0.0000\n",
      "Epoch 28 - Validation loss_nat_1: 0.8077\n",
      "Epoch 28 - Validation loss_nat_2: 0.2692\n",
      "Epoch 28 - Validation loss_1: 0.0000\n",
      "Epoch 28 - Validation loss_2: 0.8654\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.2182 - acc: 0.9625 - val_loss: 0.0103 - val_acc: 0.9900\n",
      "Epoch 29 - Validation Loss: 0.0000\n",
      "Epoch 29 - Validation loss_nat_1: 0.8077\n",
      "Epoch 29 - Validation loss_nat_2: 0.3462\n",
      "Epoch 29 - Validation loss_1: 0.0000\n",
      "Epoch 29 - Validation loss_2: 0.8654\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.1230 - acc: 0.9800 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 30 - Validation Loss: 0.0000\n",
      "Epoch 30 - Validation loss_nat_1: 0.8077\n",
      "Epoch 30 - Validation loss_nat_2: 0.3269\n",
      "Epoch 30 - Validation loss_1: 0.0000\n",
      "Epoch 30 - Validation loss_2: 0.8654\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.1309 - acc: 0.9775 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 31 - Validation Loss: 0.0000\n",
      "Epoch 31 - Validation loss_nat_1: 0.8077\n",
      "Epoch 31 - Validation loss_nat_2: 0.3269\n",
      "Epoch 31 - Validation loss_1: 0.0000\n",
      "Epoch 31 - Validation loss_2: 0.8654\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.2852 - acc: 0.9500 - val_loss: 3.5998e-04 - val_acc: 1.0000\n",
      "Epoch 32 - Validation Loss: 0.0000\n",
      "Epoch 32 - Validation loss_nat_1: 0.8077\n",
      "Epoch 32 - Validation loss_nat_2: 0.3462\n",
      "Epoch 32 - Validation loss_1: 0.0000\n",
      "Epoch 32 - Validation loss_2: 0.8462\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.1829 - acc: 0.9725 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 33 - Validation Loss: 0.0000\n",
      "Epoch 33 - Validation loss_nat_1: 0.8077\n",
      "Epoch 33 - Validation loss_nat_2: 0.2308\n",
      "Epoch 33 - Validation loss_1: 0.0000\n",
      "Epoch 33 - Validation loss_2: 0.8654\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.0781 - acc: 0.9875 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 34 - Validation Loss: 0.0000\n",
      "Epoch 34 - Validation loss_nat_1: 0.8077\n",
      "Epoch 34 - Validation loss_nat_2: 0.2308\n",
      "Epoch 34 - Validation loss_1: 0.0000\n",
      "Epoch 34 - Validation loss_2: 0.8462\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 0.0363 - acc: 0.9925 - val_loss: 1.9967e-04 - val_acc: 1.0000\n",
      "Epoch 35 - Validation Loss: 0.0000\n",
      "Epoch 35 - Validation loss_nat_1: 0.8077\n",
      "Epoch 35 - Validation loss_nat_2: 0.2500\n",
      "Epoch 35 - Validation loss_1: 0.0000\n",
      "Epoch 35 - Validation loss_2: 0.8654\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.0768 - acc: 0.9825 - val_loss: 0.0055 - val_acc: 1.0000\n",
      "Epoch 36 - Validation Loss: 0.0000\n",
      "Epoch 36 - Validation loss_nat_1: 0.8077\n",
      "Epoch 36 - Validation loss_nat_2: 0.2500\n",
      "Epoch 36 - Validation loss_1: 0.0000\n",
      "Epoch 36 - Validation loss_2: 0.8846\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.1399 - acc: 0.9825 - val_loss: 3.1048e-04 - val_acc: 1.0000\n",
      "Epoch 37 - Validation Loss: 0.0000\n",
      "Epoch 37 - Validation loss_nat_1: 0.8077\n",
      "Epoch 37 - Validation loss_nat_2: 0.2500\n",
      "Epoch 37 - Validation loss_1: 0.0000\n",
      "Epoch 37 - Validation loss_2: 0.8654\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 0.0606 - acc: 0.9925 - val_loss: 3.3312e-04 - val_acc: 1.0000\n",
      "Epoch 38 - Validation Loss: 0.0000\n",
      "Epoch 38 - Validation loss_nat_1: 0.8077\n",
      "Epoch 38 - Validation loss_nat_2: 0.2308\n",
      "Epoch 38 - Validation loss_1: 0.0000\n",
      "Epoch 38 - Validation loss_2: 0.8654\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.0056 - acc: 0.9950 - val_loss: 2.6587e-04 - val_acc: 1.0000\n",
      "Epoch 39 - Validation Loss: 0.0000\n",
      "Epoch 39 - Validation loss_nat_1: 0.8077\n",
      "Epoch 39 - Validation loss_nat_2: 0.2692\n",
      "Epoch 39 - Validation loss_1: 0.0000\n",
      "Epoch 39 - Validation loss_2: 0.8462\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 0.1282 - acc: 0.9800 - val_loss: 0.0153 - val_acc: 0.9800\n",
      "Epoch 40 - Validation Loss: 0.0000\n",
      "Epoch 40 - Validation loss_nat_1: 0.8077\n",
      "Epoch 40 - Validation loss_nat_2: 0.2692\n",
      "Epoch 40 - Validation loss_1: 0.0000\n",
      "Epoch 40 - Validation loss_2: 0.8654\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): \n",
    "\n",
    "    perturbed_model.compile(loss=negative_cross_entropy,\n",
    "                      optimizer=optimizer_purt, \n",
    "                      metrics=['accuracy'])\n",
    "    print(\"perturbed_model done\")\n",
    "\n",
    "    perturbed_model.fit_generator(train_generator, \n",
    "                                      steps_per_epoch=len(target_model.trainX) / target_model.batch_size,\n",
    "                                      validation_data=val_generator,\n",
    "                                      epochs=40,\n",
    "                                      validation_steps=len(target_model.valX) / target_model.batch_size,\n",
    "                                      callbacks=[custom_callback]\n",
    "                                      )\n",
    "    \n",
    "    perturbed_model.set_weights(custom_callback.get_best_weights())\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "    # mask <= perturbed\n",
    "    mask_model.set_weights(perturbed_model.get_weights())\n",
    "\n",
    "    mask_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer=optimizer_mask, \n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    mask_model.fit_generator(train_generator, \n",
    "                                      steps_per_epoch=len(target_model.trainX) / target_model.batch_size,\n",
    "                                      validation_data=val_generator,\n",
    "                                      epochs=40,\n",
    "                                      validation_steps=len(target_model.valX) / target_model.batch_size,\n",
    "                                      callbacks=[custom_callback_mask]\n",
    "                                      )\n",
    "    \n",
    "    mask_model.set_weights(custom_callback_mask.get_best_weights())\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "    # mask => perturbed\n",
    "    perturbed_model.set_weights(mask_model.get_weights())\n",
    "\n",
    "    robust_target.append(np.mean(loss_rob_target[(i-1)*40 : i*40]))\n",
    "    robust_trojan.append(np.mean(loss_rob_trojan[(i-1)*40 : i*40]))\n",
    "    natural_target.append(np.mean(loss_nat_target[(i-1)*40 : i*40]))\n",
    "    natural_trojan.append(np.mean(loss_nat_trojan[(i-1)*40 : i*40]))\n",
    "    loss_sequential_1.append(a*robust_target[i-1]+(1-a)*natural_target[i-1])\n",
    "    loss_sequential_2.append(a*robust_trojan[i-1]+(1-a)*natural_trojan[i-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_per,label=\"error rate\")\n",
    "plt.plot(loss_rob_target,label=\"Robustness of Target\")\n",
    "plt.plot(loss_rob_trojan,label=\"Robustness of Trojan\")\n",
    "plt.legend(loc=\"upper right\", ncol=1)\n",
    "plt.title(\"the robustness of target layer and trojan layers\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_mask,label=\"error rate\")\n",
    "plt.plot(loss_nat_target,label=\"Sensitivity of Target\")\n",
    "plt.plot(loss_nat_trojan,label=\"Sensitivity of Trojan\")\n",
    "plt.legend(loc=\"upper right\", ncol=1)\n",
    "plt.title(\"the sensitivity of target layer and trojan layers on clean data\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, 0.4766346153846153, 0.5494230769230769, 0.5388461538461539]\n",
      "[nan, nan, 0.20721153846153845, 0.20153846153846156, 0.2658653846153846]\n"
     ]
    }
   ],
   "source": [
    "print(loss_sequential_1)\n",
    "print(loss_sequential_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TrojanNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
